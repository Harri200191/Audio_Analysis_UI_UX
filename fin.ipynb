{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import speech_recognition as sr \n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer \n",
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "from pydub import AudioSegment  \n",
    "from transformers import pipeline\n",
    "import spacy\n",
    "import moviepy.editor as mp \n",
    "from moviepy.editor import VideoFileClip  \n",
    "from googletrans import Translator\n",
    "from gensim.summarization import summarize\n",
    "from openai import OpenAI\n",
    "import math\n",
    "import re\n",
    "import subprocess\n",
    "import string\n",
    "from dotenv import load_dotenv\n",
    "import pysrt\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_srt_to_string(srt_file_path): \n",
    "    subs = pysrt.open(srt_file_path) \n",
    "    converted_content = '' \n",
    "    finstr = ''\n",
    "    for sub in subs:  \n",
    "        finstr += sub.text + ' '\n",
    "        start_time = sub.start.to_time().strftime(\"%H:%M:%S,%f\")[:-3]\n",
    "        end_time = sub.end.to_time().strftime(\"%H:%M:%S,%f\")[:-3] \n",
    "        converted_content += f\"\\n<strong>[{start_time} --> {end_time}]</strong>: {sub.text}\\n\"\n",
    "\n",
    "    return converted_content.strip(), finstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hindi.mp4\n",
      "MoviePy - Writing audio in uploads\\Haris_Rehman\\hindi.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [19/Apr/2024 15:05:47] \"POST /api/convert-video-to-mp3 HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [19/Apr/2024 15:05:54] \"POST /api/convert-mp4-to-text HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Apr/2024 15:05:56] \"GET /api/translate_toen/%20Namaskar,%20Mira%20Nam%20language%20in%20Pei,%20%20or%20May%20hyper%20polyglot%20gigachad%20alpha%20mel%20hum.%20%20Miri%20Umar%20Chobes%20Salhe,%20or%20May%20America%20Sei%20hum.%20%20May%20Hindissi%20Krahahum,%20%20Kyungke%20Moojilak%20Thaheki,%20%20Modisab%20Sei%20Bahut,%20Sei%20Bahut,%20Bahut,%20Sundarhe.%20%20Or%20May%20Baharet,%20Jan%20Achaathahum,%20%20or%20May, HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Apr/2024 15:05:57] \"POST /api/analyze-audio/Namaskar,%20mira%20nam%20language%20in%20pei,%20or%20may%20hyper%20polyglot%20gigachad%20alpha%20mel%20hum.Miri%20Umar%20Chobes%20Salhe,%20or%20May%20America%20Sei%20Hum.May%20Hindissi%20Krahhum,%20Kyungke%20Moojilak%20Thaheki,%20Modisab%20Sei%20Bahut,%20Sei%20Bahut,%20Bahut,%20Sundarhe.Or%20may%20baharat,%20jan%20achaathahum,%20or%20may, HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-xsum and are newly initialized: ['model.encoder.embed_positions.weight', 'model.decoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "app = Flask(__name__)\n",
    "CORS(app, origins=\"http://localhost:3000\", supports_credentials=True)\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "@app.route('/api/analyze-audio/<string:text>', methods=['POST'])\n",
    "def analyze_text(text):\n",
    "    if len(text) == 0:\n",
    "        return jsonify({'error': 'No text provided'}), 400\n",
    "    \n",
    "    doc = nlp(text) \n",
    "    person_count = len([ent.text for ent in doc.ents if ent.label_ == \"PERSON\"]) \n",
    "    topics = [token.text for token in doc if token.is_alpha and not token.is_stop]\n",
    "\n",
    "    name = request.form['name']\n",
    "    file = request.files['file']\n",
    "\n",
    "    name = name.strip()\n",
    "    name = name.replace(\" \", \"_\")\n",
    "\n",
    "    directory_path = os.path.join('uploads', name) \n",
    "    filesname, extension = os.path.splitext(file.filename)\n",
    "    filesname = filesname.strip()\n",
    "    filesname = filesname.replace(\" \", \"_\")\n",
    "    text_path = os.path.join(directory_path, \"{}.txt\".format(filesname))  \n",
    "\n",
    "    with open(text_path, 'a') as fil:\n",
    "        fil.write(\"\\nPerson Count: {}\\n\".format(str(person_count + 1)))\n",
    "   \n",
    "    return jsonify({'person_count' : person_count + 1 , 'topic' : topics[0]})\n",
    "\n",
    "@app.route('/api/convert-video-to-mp3', methods=['POST'])\n",
    "def convert_video_to_mp3():\n",
    "    if 'file' not in request.files:\n",
    "        return jsonify({'error': 'No file provided'}), 400\n",
    "\n",
    "    video_file = request.files['file']\n",
    "    name = request.form['name']\n",
    "    name = name.strip()\n",
    "    name = name.replace(\" \", \"_\")\n",
    "\n",
    "    if video_file.filename == '':\n",
    "        return jsonify({'error': 'No selected file'}), 400\n",
    "\n",
    "    if video_file: \n",
    "        try:  \n",
    "            print(video_file.filename)\n",
    "            directory_path = os.path.join('uploads', name)\n",
    "            os.makedirs(directory_path, exist_ok=True) \n",
    "            video_path = os.path.join(directory_path, video_file.filename) \n",
    "            filesname, extension = os.path.splitext(video_file.filename)\n",
    "            audio_path = os.path.join(directory_path, \"{}.mp3\".format(filesname)) \n",
    "            video_file.save(video_path)\n",
    "            video_clip = VideoFileClip(video_path)\n",
    "            audio_clip = video_clip.audio\n",
    "            audio_clip.write_audiofile(audio_path)\n",
    "            audio_clip.close()\n",
    "            video_clip.close()\n",
    "\n",
    "            return jsonify({'message': 'Video converted to MP3 successfully', 'audio_file': audio_path}), 200\n",
    "        except Exception as e:\n",
    "            return jsonify({'error': 'Conversion error', 'details': str(e)}), 500\n",
    "\n",
    "@app.route('/api/convert-mp3-to-text', methods=['POST'])\n",
    "def convert_mp3_to_text():\n",
    "    if 'file' not in request.files:\n",
    "        return jsonify({'error': 'No file part'}), 400\n",
    "\n",
    "    file = request.files['file'] \n",
    "    name = request.form['name']\n",
    "     \n",
    "    name = name.strip()\n",
    "    name = name.replace(\" \", \"_\")\n",
    "\n",
    "    if file.filename == '':\n",
    "        return jsonify({'error': 'No selected file'}), 400\n",
    "\n",
    "    if file:  \n",
    "        filesname, extension = os.path.splitext(file.filename) \n",
    "        filesname = filesname.strip()\n",
    "        filesname = filesname.replace(\" \", \"_\")\n",
    "\n",
    "        full_filename = filesname+extension\n",
    "        directory_path = os.path.join('uploads', name)\n",
    "        os.makedirs(directory_path, exist_ok=True) \n",
    "        mp3_filename = os.path.join(directory_path, full_filename)\n",
    "\n",
    "        file.save(mp3_filename) \n",
    "        segment_dir = 'segments'  \n",
    "        os.makedirs(segment_dir, exist_ok=True)  \n",
    "        \n",
    "        #-----------------------------------------------------------------------------------------\n",
    "        command1 = f\"ffmpeg -i ./uploads/{name}/{filesname}.mp3 -ar 16000 -ac 1 -c:a pcm_s16le ./uploads/{name}/final.wav\"  \n",
    "        command2 = f\".\\\\WHISPER_EXE_FILES\\\\main.exe -f ./uploads/{name}/final.wav -m .\\\\WHISPER_EXE_FILES\\\\ggml-base.en.bin -osrt -t 8 --language auto\" \n",
    "        \n",
    "        result = subprocess.run(command1, shell=True, capture_output=True, text=True)\n",
    "        result2 = subprocess.run(command2, shell=True, capture_output=True, text=True)  \n",
    "\n",
    "        srt_file_path = f'./uploads/{name}/final.wav.srt'\n",
    "        text_path = os.path.join(directory_path, \"{}.txt\".format(filesname)) \n",
    "        result_string, joined_text = convert_srt_to_string(srt_file_path)\n",
    "        os.remove(f\"./uploads/{name}/final.wav\")\n",
    "\n",
    "        result_string = result_string.replace(\"\\n\", \"<br>\")\n",
    "\n",
    "        with open(text_path, 'w') as fil:\n",
    "            fil.write(\"\\nConverted Text: {}\\n\".format(str(joined_text)))\n",
    " \n",
    "        return jsonify({'text': joined_text, 'whisper_str': result_string})\n",
    "\n",
    "\n",
    "@app.route('/api/convert-mp4-to-text', methods=['POST'])\n",
    "def convert_mp4_to_text():\n",
    "    language = request.form['language']\n",
    "    file = request.files['file']\n",
    "    name = request.form['name']\n",
    "    \n",
    "    name = name.strip()\n",
    "    name = name.replace(\" \", \"_\")\n",
    "\n",
    "    filesname, extension = os.path.splitext(file.filename)\n",
    "    filesname = filesname.strip()\n",
    "    filesname = filesname.replace(\" \", \"_\")\n",
    "\n",
    "    file = os.path.abspath('./uploads/{}/{}.mp3'.format(name, filesname)) \n",
    "    directory_path = os.path.join('uploads', name)\n",
    "    os.makedirs(directory_path, exist_ok=True)\n",
    "    if file: \n",
    "        mp3_filename = file   \n",
    "        command1 = f\"ffmpeg -i ./uploads/{name}/{filesname}.mp3 -ar 16000 -ac 1 -c:a pcm_s16le ./uploads/{name}/final.wav\"  \n",
    "        result = subprocess.run(command1, shell=True, capture_output=True, text=True)\n",
    "\n",
    "    segment_dir = 'segments'\n",
    "    try:\n",
    "        if not os.path.exists(segment_dir):\n",
    "            os.mkdir(segment_dir)\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating directory: {e}\")\n",
    "\n",
    "\n",
    "    command2 = f\".\\\\WHISPER_EXE_FILES\\\\main.exe -f ./uploads/{name}/final.wav -m .\\\\WHISPER_EXE_FILES\\\\ggml-base.en.bin -osrt -t 8 --language auto\" \n",
    "    result2 = subprocess.run(command2, shell=True, capture_output=True, text=True)  \n",
    "\n",
    "    srt_file_path = f'./uploads/{name}/final.wav.srt'\n",
    "    text_path = os.path.join(directory_path, \"{}.txt\".format(filesname)) \n",
    "    result_string, joined_text = convert_srt_to_string(srt_file_path)\n",
    "    os.remove(f\"./uploads/{name}/final.wav\")\n",
    "    result_string = result_string.replace(\"\\n\", \"<br>\")\n",
    "\n",
    "    with open(text_path, 'w') as fil:\n",
    "        fil.write(\"\\nConverted Text: {}\\n\".format(str(joined_text)))\n",
    "\n",
    "    return jsonify({'text': joined_text, 'whisper_str': result_string})\n",
    "\n",
    "@app.route('/api/translate_toar/<string:text>', methods=['GET'], endpoint='translate_to_ar')\n",
    "def translate_to_ar(text):    \n",
    "    translator = Translator() \n",
    "    arabic_translation = translator.translate(text,  src='auto', dest='ar').text\n",
    "    return jsonify({'translated_txt': arabic_translation})\n",
    "\n",
    "@app.route('/api/translate_totr/<string:text>', methods=['GET'], endpoint='translate_to_tr')\n",
    "def translate_to_tr(text):  \n",
    "    translator = Translator()    \n",
    "\n",
    "    turkish_translation = translator.translate(text, src='auto', dest='tr').text\n",
    "    return jsonify({'translated_txt': turkish_translation})\n",
    "\n",
    "@app.route('/api/translate_toen/<string:text>', methods=['GET'], endpoint='translate_to_en')\n",
    "def translate_to_en(text):  \n",
    "    translator = Translator()    \n",
    "\n",
    "    english_translation = translator.translate(text, src='auto', dest='en').text\n",
    "    return jsonify({'translated_txt': english_translation})\n",
    "\n",
    "@app.route('/api/translate_tohi/<string:text>', methods=['GET'], endpoint='translate_to_hi')\n",
    "def translate_to_hi(text):  \n",
    "    translator = Translator()    \n",
    "\n",
    "    hindi_translation = translator.translate(text, src='auto', dest='hi').text\n",
    "    return jsonify({'translated_txt': hindi_translation})\n",
    "\n",
    "def add_newlines_every_n_words(input_string, n=10):\n",
    "    words = input_string.split()\n",
    "    output_string = ''\n",
    "    for i, word in enumerate(words):\n",
    "        if i > 0 and i % n == 0:\n",
    "            output_string += '\\n'\n",
    "        output_string += word + ' '\n",
    "    return output_string.strip()\n",
    "\n",
    "@app.route('/api/findtopic/<string:text>', methods=['POST'])\n",
    "def topic_finder(text):\n",
    "    name = request.form['name']\n",
    "    file = request.files['file']\n",
    "\n",
    "    name = name.strip()\n",
    "    name = name.replace(\" \", \"_\")\n",
    "\n",
    "    pipe = pipeline(\"text-classification\", model=\"unitary/toxic-bert\")\n",
    "    pipe2 = pipeline(\"summarization\", model=\"google/pegasus-xsum\")\n",
    "\n",
    "    topic = pipe(text)  \n",
    "    topic = topic[0]['label']\n",
    "\n",
    "    topic2 = pipe2(text, max_length = 20)\n",
    "    topic2 = topic2[0]['summary_text']\n",
    "\n",
    "    directory_path = os.path.join('uploads', name) \n",
    "    filesname, extension = os.path.splitext(file.filename)\n",
    "    filesname = filesname.strip()\n",
    "    filesname = filesname.replace(\" \", \"_\")\n",
    "    text_path = os.path.join(directory_path, \"{}.txt\".format(filesname))  \n",
    "\n",
    "    with open(text_path, 'a') as fil:\n",
    "        fil.write(\"\\nTopic: {}\\n\".format(topic2))\n",
    "    \n",
    "    return jsonify({'topic': topic, 'topic2': topic2})\n",
    "\n",
    "@app.route('/api/findSummary', methods=['POST'])\n",
    "def summary_find():\n",
    "    text = request.form['text']\n",
    "    pipe = pipeline(\"summarization\", model=\"google/pegasus-xsum\")\n",
    "    \n",
    "    temp = add_newlines_every_n_words(text, 30)\n",
    "    try: \n",
    "        summary = summarize(temp)\n",
    "        print(\"len: \", len(summary))\n",
    "    except:\n",
    "        print(\"Error in summarization using gensim\") \n",
    "        summary = \"\"\n",
    "\n",
    "    if len(summary) == 0:\n",
    "        output = pipe(text) \n",
    "        summary = output[0]['summary_text']\n",
    "             \n",
    "    translator = Translator() \n",
    "    arabic_summary = translator.translate(summary, src='en', dest='ar').text\n",
    "    turkish_summary = translator.translate(summary, src='en', dest='tr').text\n",
    "\n",
    "    name = request.form['name']\n",
    "    file = request.files['file']\n",
    "\n",
    "    name = name.strip()\n",
    "    name = name.replace(\" \", \"_\")\n",
    "\n",
    "    directory_path = os.path.join('uploads', name) \n",
    "    filesname, extension = os.path.splitext(file.filename)\n",
    "    filesname = filesname.strip()\n",
    "    filesname = filesname.replace(\" \", \"_\")\n",
    "    text_path = os.path.join(directory_path, \"{}.txt\".format(filesname))  \n",
    "\n",
    "    with open(text_path, 'a') as fil:\n",
    "        fil.write(\"\\nSummary: {}\\n\".format(str(summary)))\n",
    "\n",
    "    return jsonify({'summary_en': str(summary), 'summary_ar': arabic_summary, 'summary_tr': turkish_summary})\n",
    "\n",
    "@app.route('/api/sentiment/<string:text>', methods=['POST'])\n",
    "def sentiment(text):\n",
    "    name = request.form['name']\n",
    "    file = request.files['file']\n",
    "\n",
    "    name = name.strip()\n",
    "    name = name.replace(\" \", \"_\")\n",
    "\n",
    "    nltk.download('vader_lexicon')\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    scores = analyzer.polarity_scores(text)\n",
    "    positive_percent = round(scores['pos'] * 100, 2)\n",
    "    negative_percent = round(scores['neg'] * 100, 2)\n",
    "\n",
    "    total = positive_percent + negative_percent\n",
    "    fin_pos = round((positive_percent/total)*100, 2)\n",
    "    fin_neg = round((negative_percent/total)*100, 2) \n",
    "\n",
    "    directory_path = os.path.join('uploads', name) \n",
    "    filesname, extension = os.path.splitext(file.filename)\n",
    "    filesname = filesname.strip()\n",
    "    filesname = filesname.replace(\" \", \"_\")\n",
    "    text_path = os.path.join(directory_path, \"{}.txt\".format(filesname))  \n",
    "\n",
    "    with open(text_path, 'a') as fil:\n",
    "        fil.write(\"\\nPositive Sentiment: {}% \\nNegative Sentiment: {}%\".format(fin_pos, fin_neg))\n",
    "\n",
    "    return jsonify({'positive': fin_pos, 'negative': fin_neg})\n",
    "\n",
    "if __name__ == '__main__': \n",
    "    app.run(debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import speech_recognition as sr \n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, AutoModelForSeq2SeqLM\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer \n",
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "from pydub import AudioSegment  \n",
    "from transformers import pipeline\n",
    "import spacy\n",
    "import moviepy.editor as mp \n",
    "from moviepy.editor import VideoFileClip  \n",
    "from googletrans import Translator\n",
    "from gensim.summarization import summarize\n",
    "from openai import OpenAI\n",
    "import math\n",
    "import re\n",
    "import subprocess\n",
    "import string\n",
    "import os\n",
    "from huggingface_hub import hf_hub_download\n",
    "from dotenv import load_dotenv\n",
    "import pysrt\n",
    "import requests\n",
    "import torch\n",
    "import textrazor\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "torch.set_default_device(\"cuda\")\n",
    "\n",
    "load_dotenv() \n",
    "HUGGING_FACE_API_KEY = os.environ.get(\"HUGGING_FACE_API_KEY\")\n",
    "TEXT_RAZOR_API_KEY = os.environ.get(\"TEXT_RAZOR_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"hello again in this video we will use speech recognition module to extract text from a voice recorded in a MP3 file the main steps for these are first we need to install speech recognition module then if you have a Windows 10 machine with Python 3.8 like me you have also to install between module and with between you install this we can import and initialise the engine with MP3 file and finally extract and print the text first we need to install speech recognition so install speech recognition it enter after this we need to install because I am using Windows 10 with Python 3.80 install NTC seats with me close the terminal next we need to import speech underscore recognition AS or after this we want to initialise the engines so engine is equals to SR dot recognizer the next part is reached our MP3 file let's go a little up because I have here a function that I created and this function generates using pyttsx3 after generating the file it will return the name of that found is equals to generate MP3 file name the source then we want to say something to the end user so we print string that the file is being analysed after painting dogs record and we provide the source now let's move on to the final part let me go a little down let's put here I try and except block and let's declare a text that is equals to engine parts recognise underscore Google and we provide you after this let's print in the console our text and also we want to save in txt file so open we provide the name text from MP3 txt and next we want to write the text in our new files and we provides the text going to exception block here and and don't forget that you can download the source code also don't forget to give these video like share it with your friends subscribe and activate the bell button to get notifications about new videos that come out and as always thank you for watching\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "config.json: 100%|██████████| 1.80k/1.80k [00:00<?, ?B/s]\n",
      "pytorch_model.bin:  35%|███▌      | 430M/1.22G [02:58<07:11, 1.83MB/s] Error while downloading from https://cdn-lfs.huggingface.co/sshleifer/distilbart-cnn-12-6/3bac65d18c99463302d12ca75c2220ea714f9c81ce235f205fa818efe71df6ea?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27pytorch_model.bin%3B+filename%3D%22pytorch_model.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1714311376&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcxNDMxMTM3Nn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9zc2hsZWlmZXIvZGlzdGlsYmFydC1jbm4tMTItNi8zYmFjNjVkMThjOTk0NjMzMDJkMTJjYTc1YzIyMjBlYTcxNGY5YzgxY2UyMzVmMjA1ZmE4MThlZmU3MWRmNmVhP3Jlc3BvbnNlLWNvbnRlbnQtZGlzcG9zaXRpb249KiZyZXNwb25zZS1jb250ZW50LXR5cGU9KiJ9XX0_&Signature=Bdsovd9Wsx%7E2mAnIgiRO9K2YwZO9UuOv2dXLzDXGycm4zOnWA9Vvvc7QX97OP1N2mT1SA5aEVPaEnKWrCJPFlnFzisBwEHlt3%7EyhiOESSTibkIt%7EO41GLVi8-ZvulTfsKQiTGd7MgoJSzaulv3DhArJjwx8pUXXg3CIK1ghOlIsQCvV3zklQ483LTIes%7E9eDVmBqu0Tcp5E1ImU0ZR2XIw5M3XeEiKs-EqRC0F-SqLBe%7E62J9YHyQPmJr%7EtPUAk2hV9BuV607SqqCWLHAmV2%7EQjzyeuWNi7PH1wNMVJ2mn-6Io0aAou%7E8ashNVYjHgTUsA8LqJZBzQ%7EioiPOynIrNQ__&Key-Pair-Id=KVTP0A1DKRTAX: HTTPSConnectionPool(host='cdn-lfs.huggingface.co', port=443): Read timed out.\n",
      "Trying to resume download...\n",
      "pytorch_model.bin:  43%|████▎     | 524M/1.22G [02:46<20:28, 568kB/s]\n",
      "pytorch_model.bin:  35%|███▌      | 430M/1.22G [05:47<10:40, 1.24MB/s]\n",
      "pytorch_model.bin:   6%|▌         | 73.4M/1.22G [02:29<36:11, 529kB/s] "
     ]
    }
   ],
   "source": [
    "summarizer = pipeline(\"summarization\")\n",
    "text = summarize(prompt, max_length=130, min_length=30, do_sample=False)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engine 0.1235 1.095 ['/book/book_subject']\n",
      "Google 0.2969 12.17 ['/organization/organization_member', '/influence/influence_node', '/business/consumer_company', '/computer/operating_system_developer', '/conferences/conference_sponsor', '/internet/website_owner', '/venture_capital/venture_funded_company', '/business/brand', '/dataworld/data_provider', '/computer/computer_manufacturer_brand', '/education/educational_institution', '/travel/hotel_grading_authority', '/venture_capital/venture_investor', '/business/business_operation', '/law/litigant', '/organization/organization_founder', '/book/book_subject', '/computer/software_developer', '/award/ranked_item', '/organization/organization', '/business/sponsor', '/award/award_presenting_organization', '/award/award_winner', '/business/customer', '/organization/organization_partnership', '/business/issuer', '/law/patent_assignee', '/film/film_subject', '/conferences/conference_subject', '/computer/programming_language_developer', '/award/award_nominee', '/architecture/architectural_structure_owner', '/dataworld/information_source', '/projects/project_participant', '/business/employer']\n",
      "Command-line interface 0.4697 1.07 ['/computer/computing_platform']\n",
      "Text file 0.4256 2.187 ['/computer/file_format_genre']\n",
      "Source code 0.2887 11.2 ['/media_common/quotation_subject']\n",
      "Button 0.05268 0.9909 ['/interests/collection_category', '/law/invention', '/business/product_category']\n",
      "Text file 0.4256 2.187 ['/computer/file_format_genre']\n",
      "Speech recognition 0.3009 5.903 ['/book/book_subject', '/education/field_of_study']\n",
      "Speech recognition 0.3009 5.903 ['/book/book_subject', '/education/field_of_study']\n",
      "Speech recognition 0.3009 5.903 ['/book/book_subject', '/education/field_of_study']\n",
      "MP3 0.3065 6.179 ['/computer/file_format']\n",
      "MP3 0.3065 6.179 ['/computer/file_format']\n",
      "MP3 0.3065 6.179 ['/computer/file_format']\n",
      "MP3 0.3065 6.179 ['/computer/file_format']\n",
      "Windows 10 0.4271 2.979 ['/computer/operating_system']\n",
      "Python (programming language) 0.3657 7.259 ['/interests/hobbyist', '/conferences/conference_subject', '/people/person', '/symbols/namesake', '/business/brand', '/internet/api', '/computer/programming_language', '/book/book_subject']\n",
      "Speech recognition 0.3009 5.903 ['/book/book_subject', '/education/field_of_study']\n",
      "MP3 0.3065 6.179 ['/computer/file_format']\n",
      "Microsoft Windows 0.3227 1.243 ['/media_common/quotation_subject', '/interests/hobby', '/law/invention', '/computer/software', '/computer/operating_system', '/cvg/game_version', '/cvg/cvg_platform', '/computer/computing_platform', '/interests/interest']\n",
      "Windows 10 0.4271 2.979 ['/computer/operating_system']\n",
      "Machine 0.1295 3.063 ['/visual_art/art_subject', '/business/product_category']\n",
      "Python (programming language) 0.3657 7.259 ['/interests/hobbyist', '/conferences/conference_subject', '/people/person', '/symbols/namesake', '/business/brand', '/internet/api', '/computer/programming_language', '/book/book_subject']\n",
      "Engine 0.1235 1.187 ['/book/book_subject']\n",
      "Microsoft Windows 0.3227 1.243 ['/media_common/quotation_subject', '/interests/hobby', '/law/invention', '/computer/software', '/computer/operating_system', '/cvg/game_version', '/cvg/cvg_platform', '/computer/computing_platform', '/interests/interest']\n",
      "Engine 0.1235 2.985 ['/book/book_subject']\n",
      "End user 0.1174 1.843 ['/business/customer']\n",
      "3.79999999999999999952 0 0.5 []\n",
      "3.79999999999999999931 0 0.5 []\n",
      "10 0 0.5 []\n",
      "10 0 0.5 []\n"
     ]
    }
   ],
   "source": [
    "textrazor.api_key = TEXT_RAZOR_API_KEY\n",
    "\n",
    "client = textrazor.TextRazor(extractors=[\"entities\", \"topics\"])\n",
    "response = client.analyze(prompt)\n",
    "\n",
    "for entity in response.entities():\n",
    "    print(entity.id, entity.relevance_score, entity.confidence_score, entity.freebase_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TextRazor Topic 0 with label Computing platforms, TextRazor Topic 1 with label Digital media, TextRazor Topic 2 with label System software, TextRazor Topic 3 with label Computer engineering, TextRazor Topic 4 with label Computer programming, TextRazor Topic 5 with label Computers, TextRazor Topic 6 with label Computer science, TextRazor Topic 7 with label Software engineering, TextRazor Topic 8 with label Computing, TextRazor Topic 9 with label Software, TextRazor Topic 10 with label Technology, TextRazor Topic 11 with label Operating system families, TextRazor Topic 12 with label Computer architecture, TextRazor Topic 13 with label Information technology, TextRazor Topic 14 with label Windows 10, TextRazor Topic 15 with label Text file, TextRazor Topic 16 with label Digital technology, TextRazor Topic 17 with label MP3, TextRazor Topic 18 with label Microsoft Windows, TextRazor Topic 19 with label Software development, TextRazor Topic 20 with label Office equipment, TextRazor Topic 21 with label Systems engineering, TextRazor Topic 22 with label Speech recognition, TextRazor Topic 23 with label Python (programming language), TextRazor Topic 24 with label Command-line interface, TextRazor Topic 25 with label Mass media technology, TextRazor Topic 26 with label Multimedia, TextRazor Topic 27 with label Programming interfaces, TextRazor Topic 28 with label IBM PC compatibles, TextRazor Topic 29 with label Application software, TextRazor Topic 30 with label X86 architecture, TextRazor Topic 31 with label Computer data, TextRazor Topic 32 with label Microsoft software, TextRazor Topic 33 with label Operating system technology, TextRazor Topic 34 with label Computer files, TextRazor Topic 35 with label Systems architecture, TextRazor Topic 36 with label Source code, TextRazor Topic 37 with label Windows NT, TextRazor Topic 38 with label Filenames, TextRazor Topic 39 with label Microsoft franchises, TextRazor Topic 40 with label Cyberspace, TextRazor Topic 41 with label Electronic publishing, TextRazor Topic 42 with label Design, TextRazor Topic 43 with label Information technology management, TextRazor Topic 44 with label Electronics industry, TextRazor Topic 45 with label Software design, TextRazor Topic 46 with label Data management, TextRazor Topic 47 with label Personal computers, TextRazor Topic 48 with label X86-based computers, TextRazor Topic 49 with label Human–computer interaction, TextRazor Topic 50 with label Utility software, TextRazor Topic 51 with label Interfaces, TextRazor Topic 52 with label Software architecture, TextRazor Topic 53 with label Cyberpunk themes, TextRazor Topic 54 with label Unix software, TextRazor Topic 55 with label Text, TextRazor Topic 56 with label Software industry, TextRazor Topic 57 with label Human communication, TextRazor Topic 58 with label Programming paradigms, TextRazor Topic 59 with label User interfaces, TextRazor Topic 60 with label Information science, TextRazor Topic 61 with label Technology development, TextRazor Topic 62 with label Engine, TextRazor Topic 63 with label Proprietary software, TextRazor Topic 64 with label Naming conventions, TextRazor Topic 65 with label Microcomputer software, TextRazor Topic 66 with label Data, TextRazor Topic 67 with label Classes of computers, TextRazor Topic 68 with label Graphical user interfaces, TextRazor Topic 69 with label Notation, TextRazor Topic 70 with label Storage media, TextRazor Topic 71 with label Arts, TextRazor Topic 72 with label Interoperability, TextRazor Topic 73 with label Information and communications technology, TextRazor Topic 74 with label Telecommunications, TextRazor Topic 75 with label Object-oriented programming, TextRazor Topic 76 with label Online services, TextRazor Topic 77 with label Computer file formats, TextRazor Topic 78 with label Writing, TextRazor Topic 79 with label IT infrastructure, TextRazor Topic 80 with label Computer hardware, TextRazor Topic 81 with label Microsoft, TextRazor Topic 82 with label Video game platforms, TextRazor Topic 83 with label Engineering, TextRazor Topic 84 with label Internet, TextRazor Topic 85 with label Cross-platform software, TextRazor Topic 86 with label Personal computing, TextRazor Topic 87 with label Windows components, TextRazor Topic 88 with label Consumer electronics, TextRazor Topic 89 with label Programming tools, TextRazor Topic 90 with label Centralized computing, TextRazor Topic 91 with label World Wide Web, TextRazor Topic 92 with label Machine, TextRazor Topic 93 with label Language, TextRazor Topic 94 with label Computer-mediated communication, TextRazor Topic 95 with label Filename extensions, TextRazor Topic 96 with label Free software, TextRazor Topic 97 with label Linguistics, TextRazor Topic 98 with label End user, TextRazor Topic 99 with label User interface techniques, TextRazor Topic 100 with label Operating system components, TextRazor Topic 101 with label Applications of artificial intelligence, TextRazor Topic 102 with label Mobile software, TextRazor Topic 103 with label Human–machine interaction, TextRazor Topic 104 with label Computing commands, TextRazor Topic 105 with label Computer networking, TextRazor Topic 106 with label Microcomputers, TextRazor Topic 107 with label Windows files, TextRazor Topic 108 with label Applied mathematics, TextRazor Topic 109 with label Metadata, TextRazor Topic 110 with label Object (computer science), TextRazor Topic 111 with label Models of computation, TextRazor Topic 112 with label Information appliances, TextRazor Topic 113 with label ARM architecture, TextRazor Topic 114 with label Service industries, TextRazor Topic 115 with label Alternate reality, TextRazor Topic 116 with label Mobile computers, TextRazor Topic 117 with label Distributed computing architecture, TextRazor Topic 118 with label Compilers, TextRazor Topic 119 with label Information retrieval, TextRazor Topic 120 with label Theoretical computer science, TextRazor Topic 121 with label Unix, TextRazor Topic 122 with label Telecommunications engineering, TextRazor Topic 123 with label Science software, TextRazor Topic 124 with label Software companies of the United States, TextRazor Topic 125 with label Computer hardware clones, TextRazor Topic 126 with label Components, TextRazor Topic 127 with label Written communication, TextRazor Topic 128 with label Information Age, TextRazor Topic 129 with label Redirects from media types, TextRazor Topic 130 with label Educational technology, TextRazor Topic 131 with label Discontinued products, TextRazor Topic 132 with label Artificial intelligence, TextRazor Topic 133 with label Google, TextRazor Topic 134 with label Video, TextRazor Topic 135 with label Web 2.0, TextRazor Topic 136 with label Smartphones, TextRazor Topic 137 with label Voice technology, TextRazor Topic 138 with label Business computing, TextRazor Topic 139 with label New media, TextRazor Topic 140 with label Computing redirects, TextRazor Topic 141 with label Grammar, TextRazor Topic 142 with label Algorithms, TextRazor Topic 143 with label Scientific modelling, TextRazor Topic 144 with label Machines, TextRazor Topic 145 with label Linux software, TextRazor Topic 146 with label Video game consoles, TextRazor Topic 147 with label Main namespace redirects, TextRazor Topic 148 with label Digital audio, TextRazor Topic 149 with label Publishing, TextRazor Topic 150 with label Tablet computers, TextRazor Topic 151 with label Websites, TextRazor Topic 152 with label Linux, TextRazor Topic 153 with label Internet Protocol based network software, TextRazor Topic 154 with label Presentation layer protocols, TextRazor Topic 155 with label Systems thinking, TextRazor Topic 156 with label Tools, TextRazor Topic 157 with label Identifiers, TextRazor Topic 158 with label Electronics, TextRazor Topic 159 with label Video game hardware, TextRazor Topic 160 with label Computational linguistics, TextRazor Topic 161 with label Windows commands, TextRazor Topic 162 with label Programming constructs, TextRazor Topic 163 with label Equipment, TextRazor Topic 164 with label Speech, TextRazor Topic 165 with label Communication software, TextRazor Topic 166 with label Cognitive science, TextRazor Topic 167 with label Manufactured goods, TextRazor Topic 168 with label Assistive technology, TextRazor Topic 169 with label Macintosh software, TextRazor Topic 170 with label Video gaming, TextRazor Topic 171 with label Collective intelligence, TextRazor Topic 172 with label Web software, TextRazor Topic 173 with label Information management, TextRazor Topic 174 with label Formalism (deductive), TextRazor Topic 175 with label Distribution (marketing), TextRazor Topic 176 with label Storage software, TextRazor Topic 177 with label Information economy, TextRazor Topic 178 with label Branches of linguistics, TextRazor Topic 179 with label Grouping, TextRazor Topic 180 with label Free and open-source software, TextRazor Topic 181 with label Computational social science, TextRazor Topic 182 with label Signal processing, TextRazor Topic 183 with label Audio compression, TextRazor Topic 184 with label Encodings, TextRazor Topic 185 with label Implementation, TextRazor Topic 186 with label Mobile phones, TextRazor Topic 187 with label Multimedia software, TextRazor Topic 188 with label X86-based game consoles, TextRazor Topic 189 with label E-commerce, TextRazor Topic 190 with label Learning, TextRazor Topic 191 with label Minicomputers, TextRazor Topic 192 with label Human voice, TextRazor Topic 193 with label Computational neuroscience, TextRazor Topic 194 with label Applied linguistics, TextRazor Topic 195 with label Microsoft games, TextRazor Topic 196 with label Application layer protocols, TextRazor Topic 197 with label Computer companies of the United States, TextRazor Topic 198 with label Audio software, TextRazor Topic 199 with label Sound technology, TextRazor Topic 200 with label Home video game consoles, TextRazor Topic 201 with label Mass media, TextRazor Topic 202 with label Computer industry, TextRazor Topic 203 with label Web applications, TextRazor Topic 204 with label Windows Vista, TextRazor Topic 205 with label Computer libraries, TextRazor Topic 206 with label Applications of cryptography, TextRazor Topic 207 with label Mathematical logic, TextRazor Topic 208 with label Hardlines (retail), TextRazor Topic 209 with label DOS on IBM PC compatibles, TextRazor Topic 210 with label Electrical engineering, TextRazor Topic 211 with label Computational science, TextRazor Topic 212 with label Film and video technology, TextRazor Topic 213 with label Audio codecs, TextRazor Topic 214 with label Security engineering, TextRazor Topic 215 with label Coding theory, TextRazor Topic 216 with label Discontinued Microsoft software, TextRazor Topic 217 with label Lossy compression algorithms, TextRazor Topic 218 with label Data compression]\n"
     ]
    }
   ],
   "source": [
    "print(response.topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_srt_to_string(srt_file_path): \n",
    "    subs = pysrt.open(srt_file_path) \n",
    "    converted_content = '' \n",
    "    finstr = ''\n",
    "    for sub in subs:  \n",
    "        finstr += sub.text + ' '\n",
    "        start_time = sub.start.to_time().strftime(\"%H:%M:%S,%f\")[:-3]\n",
    "        end_time = sub.end.to_time().strftime(\"%H:%M:%S,%f\")[:-3] \n",
    "        converted_content += f\"\\n<strong>[{start_time} --> {end_time}]</strong>: {sub.text}\\n\"\n",
    "\n",
    "    return converted_content.strip(), finstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)\n",
    "CORS(app, origins=\"http://localhost:3000\", supports_credentials=True)\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "@app.route('/api/analyze-audio/<string:text>', methods=['POST'])\n",
    "def analyze_text(text):\n",
    "    if len(text) == 0:\n",
    "        return jsonify({'error': 'No text provided'}), 400\n",
    "    \n",
    "    doc = nlp(text) \n",
    "    person_count = len([ent.text for ent in doc.ents if ent.label_ == \"PERSON\"]) \n",
    "    topics = [token.text for token in doc if token.is_alpha and not token.is_stop]\n",
    "\n",
    "    name = request.form['name']\n",
    "    file = request.files['file']\n",
    "\n",
    "    name = name.strip()\n",
    "    name = name.replace(\" \", \"_\")\n",
    "\n",
    "    directory_path = os.path.join('uploads', name) \n",
    "    filesname, extension = os.path.splitext(file.filename)\n",
    "    filesname = filesname.strip()\n",
    "    filesname = filesname.replace(\" \", \"_\")\n",
    "    text_path = os.path.join(directory_path, \"{}.txt\".format(filesname))  \n",
    "\n",
    "    with open(text_path, 'a') as fil:\n",
    "        fil.write(\"\\nPerson Count: {}\\n\".format(str(person_count + 1)))\n",
    "   \n",
    "    return jsonify({'person_count' : person_count + 1 , 'topic' : topics[0]})\n",
    "\n",
    "@app.route('/api/convert-video-to-mp3', methods=['POST'])\n",
    "def convert_video_to_mp3():\n",
    "    if 'file' not in request.files:\n",
    "        return jsonify({'error': 'No file provided'}), 400\n",
    "\n",
    "    video_file = request.files['file']\n",
    "    name = request.form['name']\n",
    "    name = name.strip()\n",
    "    name = name.replace(\" \", \"_\")\n",
    "\n",
    "    if video_file.filename == '':\n",
    "        return jsonify({'error': 'No selected file'}), 400\n",
    "\n",
    "    if video_file: \n",
    "        try:  \n",
    "            print(video_file.filename)\n",
    "            directory_path = os.path.join('uploads', name)\n",
    "            os.makedirs(directory_path, exist_ok=True) \n",
    "            video_path = os.path.join(directory_path, video_file.filename) \n",
    "            filesname, extension = os.path.splitext(video_file.filename)\n",
    "            audio_path = os.path.join(directory_path, \"{}.mp3\".format(filesname)) \n",
    "            video_file.save(video_path)\n",
    "            video_clip = VideoFileClip(video_path)\n",
    "            audio_clip = video_clip.audio\n",
    "            audio_clip.write_audiofile(audio_path)\n",
    "            audio_clip.close()\n",
    "            video_clip.close()\n",
    "\n",
    "            return jsonify({'message': 'Video converted to MP3 successfully', 'audio_file': audio_path}), 200\n",
    "        except Exception as e:\n",
    "            return jsonify({'error': 'Conversion error', 'details': str(e)}), 500\n",
    "\n",
    "@app.route('/api/convert-mp3-to-text', methods=['POST'])\n",
    "def convert_mp3_to_text():\n",
    "    if 'file' not in request.files:\n",
    "        return jsonify({'error': 'No file part'}), 400\n",
    "\n",
    "    file = request.files['file'] \n",
    "    name = request.form['name']\n",
    "     \n",
    "    name = name.strip()\n",
    "    name = name.replace(\" \", \"_\")\n",
    "\n",
    "    if file.filename == '':\n",
    "        return jsonify({'error': 'No selected file'}), 400\n",
    "\n",
    "    if file:  \n",
    "        filesname, extension = os.path.splitext(file.filename) \n",
    "        filesname = filesname.strip()\n",
    "        filesname = filesname.replace(\" \", \"_\")\n",
    "\n",
    "        full_filename = filesname+extension\n",
    "        directory_path = os.path.join('uploads', name)\n",
    "        os.makedirs(directory_path, exist_ok=True) \n",
    "        mp3_filename = os.path.join(directory_path, full_filename)\n",
    "\n",
    "        file.save(mp3_filename) \n",
    "        segment_dir = 'segments'  \n",
    "        os.makedirs(segment_dir, exist_ok=True)  \n",
    "        \n",
    "        #-----------------------------------------------------------------------------------------\n",
    "        command1 = f\"ffmpeg -i ./uploads/{name}/{filesname}.mp3 -ar 16000 -ac 1 -c:a pcm_s16le ./uploads/{name}/final.wav\"  \n",
    "        command2 = f\".\\\\WHISPER_EXE_FILES\\\\main.exe -f ./uploads/{name}/final.wav -m .\\\\WHISPER_EXE_FILES\\\\ggml-base.en.bin -osrt -t 8 --language auto\" \n",
    "        \n",
    "        result = subprocess.run(command1, shell=True, capture_output=True, text=True)\n",
    "        result2 = subprocess.run(command2, shell=True, capture_output=True, text=True)  \n",
    "\n",
    "        srt_file_path = f'./uploads/{name}/final.wav.srt'\n",
    "        text_path = os.path.join(directory_path, \"{}.txt\".format(filesname)) \n",
    "        result_string, joined_text = convert_srt_to_string(srt_file_path)\n",
    "        os.remove(f\"./uploads/{name}/final.wav\")\n",
    "\n",
    "        result_string = result_string.replace(\"\\n\", \"<br>\")\n",
    "\n",
    "        with open(text_path, 'w') as fil:\n",
    "            fil.write(\"\\nConverted Text: {}\\n\".format(str(joined_text)))\n",
    " \n",
    "        return jsonify({'text': joined_text, 'whisper_str': result_string})\n",
    "\n",
    "@app.route('/api/convert-mp4-to-text', methods=['POST'])\n",
    "def convert_mp4_to_text():\n",
    "    language = request.form['language']\n",
    "    file = request.files['file']\n",
    "    name = request.form['name']\n",
    "    \n",
    "    name = name.strip()\n",
    "    name = name.replace(\" \", \"_\")\n",
    "\n",
    "    filesname, extension = os.path.splitext(file.filename)\n",
    "    filesname = filesname.strip()\n",
    "    filesname = filesname.replace(\" \", \"_\")\n",
    "\n",
    "    file = os.path.abspath('./uploads/{}/{}.mp3'.format(name, filesname)) \n",
    "    directory_path = os.path.join('uploads', name)\n",
    "    os.makedirs(directory_path, exist_ok=True)\n",
    "    if file: \n",
    "        mp3_filename = file   \n",
    "        command1 = f\"ffmpeg -i ./uploads/{name}/{filesname}.mp3 -ar 16000 -ac 1 -c:a pcm_s16le ./uploads/{name}/final.wav\"  \n",
    "        result = subprocess.run(command1, shell=True, capture_output=True, text=True)\n",
    "\n",
    "    segment_dir = 'segments'\n",
    "    try:\n",
    "        if not os.path.exists(segment_dir):\n",
    "            os.mkdir(segment_dir)\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating directory: {e}\")\n",
    "\n",
    "\n",
    "    command2 = f\".\\\\WHISPER_EXE_FILES\\\\main.exe -f ./uploads/{name}/final.wav -m .\\\\WHISPER_EXE_FILES\\\\ggml-base.en.bin -osrt -t 8 --language auto\" \n",
    "    result2 = subprocess.run(command2, shell=True, capture_output=True, text=True)  \n",
    "\n",
    "    srt_file_path = f'./uploads/{name}/final.wav.srt'\n",
    "    text_path = os.path.join(directory_path, \"{}.txt\".format(filesname)) \n",
    "    result_string, joined_text = convert_srt_to_string(srt_file_path)\n",
    "    os.remove(f\"./uploads/{name}/final.wav\")\n",
    "    result_string = result_string.replace(\"\\n\", \"<br>\")\n",
    "\n",
    "    with open(text_path, 'w') as fil:\n",
    "        fil.write(\"\\nConverted Text: {}\\n\".format(str(joined_text)))\n",
    "\n",
    "    return jsonify({'text': joined_text, 'whisper_str': result_string})\n",
    "\n",
    "@app.route('/api/translate_toar/<string:text>', methods=['GET'], endpoint='translate_to_ar')\n",
    "def translate_to_ar(text):    \n",
    "    translator = Translator() \n",
    "    arabic_translation = translator.translate(text,  src='auto', dest='ar').text\n",
    "    return jsonify({'translated_txt': arabic_translation})\n",
    "\n",
    "@app.route('/api/translate_totr/<string:text>', methods=['GET'], endpoint='translate_to_tr')\n",
    "def translate_to_tr(text):  \n",
    "    translator = Translator()    \n",
    "\n",
    "    turkish_translation = translator.translate(text, src='auto', dest='tr').text\n",
    "    return jsonify({'translated_txt': turkish_translation})\n",
    "\n",
    "@app.route('/api/translate_toen/<string:text>', methods=['GET'], endpoint='translate_to_en')\n",
    "def translate_to_en(text):  \n",
    "    translator = Translator()    \n",
    "\n",
    "    english_translation = translator.translate(text, src='auto', dest='en').text\n",
    "    return jsonify({'translated_txt': english_translation})\n",
    "\n",
    "@app.route('/api/translate_tohi/<string:text>', methods=['GET'], endpoint='translate_to_hi')\n",
    "def translate_to_hi(text):  \n",
    "    translator = Translator()    \n",
    "\n",
    "    hindi_translation = translator.translate(text, src='auto', dest='hi').text\n",
    "    return jsonify({'translated_txt': hindi_translation})\n",
    "\n",
    "def add_newlines_every_n_words(input_string, n=10):\n",
    "    words = input_string.split()\n",
    "    output_string = ''\n",
    "    for i, word in enumerate(words):\n",
    "        if i > 0 and i % n == 0:\n",
    "            output_string += '\\n'\n",
    "        output_string += word + ' '\n",
    "    return output_string.strip()\n",
    "\n",
    "@app.route('/api/findtopic/<string:text>', methods=['POST'])\n",
    "def topic_finder(text):\n",
    "    name = request.form['name']\n",
    "    file = request.files['file']\n",
    "\n",
    "    name = name.strip()\n",
    "    name = name.replace(\" \", \"_\")\n",
    "\n",
    "    pipe = pipeline(\"text-classification\", model=\"unitary/toxic-bert\")\n",
    "    pipe2 = pipeline(\"summarization\", model=\"google/pegasus-xsum\")\n",
    "\n",
    "    topic = pipe(text)  \n",
    "    topic = topic[0]['label']\n",
    "\n",
    "    topic2 = pipe2(text, max_length = 20)\n",
    "    topic2 = topic2[0]['summary_text']\n",
    "\n",
    "    directory_path = os.path.join('uploads', name) \n",
    "    filesname, extension = os.path.splitext(file.filename)\n",
    "    filesname = filesname.strip()\n",
    "    filesname = filesname.replace(\" \", \"_\")\n",
    "    text_path = os.path.join(directory_path, \"{}.txt\".format(filesname))  \n",
    "\n",
    "    with open(text_path, 'a') as fil:\n",
    "        fil.write(\"\\nTopic: {}\\n\".format(topic2))\n",
    "    \n",
    "    return jsonify({'topic': topic, 'topic2': topic2})\n",
    "\n",
    "@app.route('/api/findSummary', methods=['POST'])\n",
    "def summary_find():\n",
    "    text = request.form['text']\n",
    "    pipe = pipeline(\"summarization\", model=\"google/pegasus-xsum\")\n",
    "    \n",
    "    temp = add_newlines_every_n_words(text, 30)\n",
    "    try: \n",
    "        summary = summarize(temp)\n",
    "        print(\"len: \", len(summary))\n",
    "    except:\n",
    "        print(\"Error in summarization using gensim\") \n",
    "        summary = \"\"\n",
    "\n",
    "    if len(summary) == 0:\n",
    "        output = pipe(text) \n",
    "        summary = output[0]['summary_text']\n",
    "             \n",
    "    translator = Translator() \n",
    "    arabic_summary = translator.translate(summary, src='en', dest='ar').text\n",
    "    turkish_summary = translator.translate(summary, src='en', dest='tr').text\n",
    "\n",
    "    name = request.form['name']\n",
    "    file = request.files['file']\n",
    "\n",
    "    name = name.strip()\n",
    "    name = name.replace(\" \", \"_\")\n",
    "\n",
    "    directory_path = os.path.join('uploads', name) \n",
    "    filesname, extension = os.path.splitext(file.filename)\n",
    "    filesname = filesname.strip()\n",
    "    filesname = filesname.replace(\" \", \"_\")\n",
    "    text_path = os.path.join(directory_path, \"{}.txt\".format(filesname))  \n",
    "\n",
    "    with open(text_path, 'a') as fil:\n",
    "        fil.write(\"\\nSummary: {}\\n\".format(str(summary)))\n",
    "\n",
    "    return jsonify({'summary_en': str(summary), 'summary_ar': arabic_summary, 'summary_tr': turkish_summary})\n",
    "\n",
    "@app.route('/api/sentiment/<string:text>', methods=['POST'])\n",
    "def sentiment(text):\n",
    "    name = request.form['name']\n",
    "    file = request.files['file']\n",
    "\n",
    "    name = name.strip()\n",
    "    name = name.replace(\" \", \"_\")\n",
    "\n",
    "    nltk.download('vader_lexicon')\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    scores = analyzer.polarity_scores(text)\n",
    "    positive_percent = round(scores['pos'] * 100, 2)\n",
    "    negative_percent = round(scores['neg'] * 100, 2)\n",
    "\n",
    "    total = positive_percent + negative_percent\n",
    "    if (total == 0):\n",
    "        fin_pos = 50\n",
    "        fin_neg = 50\n",
    "    else:\n",
    "        fin_pos = round((positive_percent/total)*100, 2)\n",
    "        fin_neg = round((negative_percent/total)*100, 2) \n",
    "\n",
    "\n",
    "    directory_path = os.path.join('uploads', name) \n",
    "    filesname, extension = os.path.splitext(file.filename)\n",
    "    filesname = filesname.strip()\n",
    "    filesname = filesname.replace(\" \", \"_\")\n",
    "    text_path = os.path.join(directory_path, \"{}.txt\".format(filesname))  \n",
    "\n",
    "    with open(text_path, 'a') as fil:\n",
    "        fil.write(\"\\nPositive Sentiment: {}% \\nNegative Sentiment: {}%\".format(fin_pos, fin_neg))\n",
    "\n",
    "    return jsonify({'positive': fin_pos, 'negative': fin_neg})\n",
    "\n",
    "if __name__ == '__main__': \n",
    "    app.run(debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

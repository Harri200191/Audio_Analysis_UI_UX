{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.0.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "try: \n",
    "    print(\"PyTorch version:\", torch.__version__)\n",
    "except ImportError: \n",
    "    print(\"PyTorch is not installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import speech_recognition as sr \n",
    "import nltk\n",
    "import string\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer \n",
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "from pydub import AudioSegment  \n",
    "from transformers import pipeline\n",
    "import spacy\n",
    "import moviepy.editor as mp \n",
    "from moviepy.editor import VideoFileClip  \n",
    "from googletrans import Translator\n",
    "from gensim.summarization import summarize\n",
    "from openai import OpenAI\n",
    "import math\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Server Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final.mp4\n",
      "MoviePy - Writing audio in uploads\\Haris Rehman\\final.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [06/Apr/2024 20:52:14] \"POST /api/convert-video-to-mp3 HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [06/Apr/2024 20:52:23] \"POST /api/convert-mp4-to-text HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Apr/2024 20:52:25] \"GET /api/translate_toen/Why%20I%20love%20Envato%20Elements?%20I%20love%20that%20I%20don't%20have%20to%20animate%20my%20own%20texting%20conversations%20in%20After%20Effects,%20because%20that's%20a%20lot%20of%20work.%20Whatever%20picture,%20sound,%20or%20graphic%20that%20I%20can%20imagine,%20Envato%20Elements%20has%20the%20thing%20to%20bring%20that%20vision%20to%20life%20and%20create%20better%20videos%20faster.%20Try%20Envato%20Elements%20now%20and%20get%20access%20to%20unlimited%20downloads%20of%20millions%20of%20creative%20assets,%20all%20covered%20with%20a%20lifetime%20commercial%20license.%20Create%20better%20videos%20faster.%20Envato%20Elements HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Apr/2024 20:52:26] \"POST /api/analyze-audio/Why%20I%20love%20Envato%20Elements HTTP/1.1\" 200 -\n",
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-xsum and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Your max_length is set to 20, but your input_length is only 8. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=4)\n",
      "127.0.0.1 - - [06/Apr/2024 20:52:46] \"POST /api/findtopic/Why%20I%20love%20Envato%20Elements HTTP/1.1\" 200 -\n",
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-xsum and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Your max_length is set to 64, but your input_length is only 8. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in summarization using gensim\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [06/Apr/2024 20:52:58] \"POST /api/findSummary HTTP/1.1\" 200 -\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\haris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "127.0.0.1 - - [06/Apr/2024 20:52:59] \"POST /api/sentiment/Why%20I%20love%20Envato%20Elements HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Apr/2024 20:53:12] \"GET /api/translate_toen/%20[0:0]%20Why%20I%20love%20Envato%20Elements%20I%20love%20that%20I%20don't%20[0:2.7]%20have%20to%20animate%20my%20own%20texting%20conversations%20in%20After%20Effects%20[0:6.4]%20because%20that's%20a%20lot%20of%20work%20Whatever%20picture%20sound%20or%20[0:9.9]%20graphic%20that%20I%20can%20imagine%20Envato%20Elements%20has%20the%20thing%20[0:13.2]%20to%20bring%20that%20vision%20to%20life%20and%20create%20better%20videos%20[0:15.9]%20faster%20Try%20Envato%20Elements%20now%20and%20get%20access%20to%20unlimited%20[0:19.4]%20downloads%20of%20millions%20of%20creative%20assets%20all%20covered%20with%20a%20[0:23.1]%20lifetime%20commercial%20license%20Create%20better%20videos%20faster%20Envato%20Elements%20[0:30.1] HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Apr/2024 20:53:14] \"GET /api/translate_tohi/Why%20I%20love%20Envato%20Elements?%20I%20love%20that%20I%20don't%20have%20to%20animate%20my%20own%20texting%20conversations%20in%20After%20Effects,%20because%20that's%20a%20lot%20of%20work.%20Whatever%20picture,%20sound,%20or%20graphic%20that%20I%20can%20imagine,%20Envato%20Elements%20has%20the%20thing%20to%20bring%20that%20vision%20to%20life%20and%20create%20better%20videos%20faster.%20Try%20Envato%20Elements%20now%20and%20get%20access%20to%20unlimited%20downloads%20of%20millions%20of%20creative%20assets,%20all%20covered%20with%20a%20lifetime%20commercial%20license.%20Create%20better%20videos%20faster.%20Envato%20Elements HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Apr/2024 20:53:17] \"GET /api/translate_totr/Why%20I%20love%20Envato%20Elements?%20I%20love%20that%20I%20don't%20have%20to%20animate%20my%20own%20texting%20conversations%20in%20After%20Effects,%20because%20that's%20a%20lot%20of%20work.%20Whatever%20picture,%20sound,%20or%20graphic%20that%20I%20can%20imagine,%20Envato%20Elements%20has%20the%20thing%20to%20bring%20that%20vision%20to%20life%20and%20create%20better%20videos%20faster.%20Try%20Envato%20Elements%20now%20and%20get%20access%20to%20unlimited%20downloads%20of%20millions%20of%20creative%20assets,%20all%20covered%20with%20a%20lifetime%20commercial%20license.%20Create%20better%20videos%20faster.%20Envato%20Elements HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Apr/2024 20:53:19] \"GET /api/translate_toar/Why%20I%20love%20Envato%20Elements?%20I%20love%20that%20I%20don't%20have%20to%20animate%20my%20own%20texting%20conversations%20in%20After%20Effects,%20because%20that's%20a%20lot%20of%20work.%20Whatever%20picture,%20sound,%20or%20graphic%20that%20I%20can%20imagine,%20Envato%20Elements%20has%20the%20thing%20to%20bring%20that%20vision%20to%20life%20and%20create%20better%20videos%20faster.%20Try%20Envato%20Elements%20now%20and%20get%20access%20to%20unlimited%20downloads%20of%20millions%20of%20creative%20assets,%20all%20covered%20with%20a%20lifetime%20commercial%20license.%20Create%20better%20videos%20faster.%20Envato%20Elements HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Apr/2024 20:53:23] \"GET /api/translate_tohi/Why%20I%20love%20Envato%20Elements?%20I%20love%20that%20I%20don't%20have%20to%20animate%20my%20own%20texting%20conversations%20in%20After%20Effects,%20because%20that's%20a%20lot%20of%20work.%20Whatever%20picture,%20sound,%20or%20graphic%20that%20I%20can%20imagine,%20Envato%20Elements%20has%20the%20thing%20to%20bring%20that%20vision%20to%20life%20and%20create%20better%20videos%20faster.%20Try%20Envato%20Elements%20now%20and%20get%20access%20to%20unlimited%20downloads%20of%20millions%20of%20creative%20assets,%20all%20covered%20with%20a%20lifetime%20commercial%20license.%20Create%20better%20videos%20faster.%20Envato%20Elements HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Apr/2024 20:53:27] \"GET /api/translate_toen/%20[0:0]%20Why%20I%20love%20Envato%20Elements%20I%20love%20that%20I%20don't%20[0:2.7]%20have%20to%20animate%20my%20own%20texting%20conversations%20in%20After%20Effects%20[0:6.4]%20because%20that's%20a%20lot%20of%20work%20Whatever%20picture%20sound%20or%20[0:9.9]%20graphic%20that%20I%20can%20imagine%20Envato%20Elements%20has%20the%20thing%20[0:13.2]%20to%20bring%20that%20vision%20to%20life%20and%20create%20better%20videos%20[0:15.9]%20faster%20Try%20Envato%20Elements%20now%20and%20get%20access%20to%20unlimited%20[0:19.4]%20downloads%20of%20millions%20of%20creative%20assets%20all%20covered%20with%20a%20[0:23.1]%20lifetime%20commercial%20license%20Create%20better%20videos%20faster%20Envato%20Elements%20[0:30.1] HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hindi.mp4\n",
      "MoviePy - Writing audio in uploads\\Haris Rehman\\hindi.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [06/Apr/2024 20:54:46] \"POST /api/convert-video-to-mp3 HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [06/Apr/2024 20:54:53] \"POST /api/convert-mp4-to-text HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Apr/2024 20:54:55] \"GET /api/translate_toen/Namaskar.%20My%20name%20is%20Language%20Zimp,%20and%20I%20am%20a%20hyperpolyglot%20gigachad%20alpha%20male.%20I%20am%2024%20years%20old,%20and%20I%20am%20from%20America.%20I%20am%20learning%20Hindi%20because%20I%20think%20it%20is%20very,%20very,%20very%20beautiful%20from%20Mr.%20Modi.%20And%20I%20want%20to%20go%20to%20India,%20and%20I... HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Apr/2024 20:54:56] \"POST /api/analyze-audio/Namaskar.%20My%20name%20is%20Language%20Zimp,%20and%20I%20am%20a%20hyperpolyglot%20gigachad%20alpha%20male.%20I%20am%2024%20years%20old,%20and%20I%20am%20from%20America.%20I%20am%20learning%20Hindi%20because%20I%20think%20it%20is%20very,%20very,%20very%20beautiful%20from%20Mr.%20Modi.%20And%20I%20want%20to%20go%20to%20India,%20and%20I... HTTP/1.1\" 200 -\n",
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-xsum and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "127.0.0.1 - - [06/Apr/2024 20:55:15] \"POST /api/findtopic/Namaskar.%20My%20name%20is%20Language%20Zimp,%20and%20I%20am%20a%20hyperpolyglot%20gigachad%20alpha%20male.%20I%20am%2024%20years%20old,%20and%20I%20am%20from%20America.%20I%20am%20learning%20Hindi%20because%20I%20think%20it%20is%20very,%20very,%20very%20beautiful%20from%20Mr.%20Modi.%20And%20I%20want%20to%20go%20to%20India,%20and%20I... HTTP/1.1\" 200 -\n",
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-xsum and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len:  9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [06/Apr/2024 20:55:30] \"POST /api/findSummary HTTP/1.1\" 200 -\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\haris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "127.0.0.1 - - [06/Apr/2024 20:55:32] \"POST /api/sentiment/Namaskar.%20My%20name%20is%20Language%20Zimp,%20and%20I%20am%20a%20hyperpolyglot%20gigachad%20alpha%20male.%20I%20am%2024%20years%20old,%20and%20I%20am%20from%20America.%20I%20am%20learning%20Hindi%20because%20I%20think%20it%20is%20very,%20very,%20very%20beautiful%20from%20Mr.%20Modi.%20And%20I%20want%20to%20go%20to%20India,%20and%20I... HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "app = Flask(__name__)\n",
    "CORS(app, origins=\"http://localhost:3000\", supports_credentials=True)\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "@app.route('/api/analyze-audio/<string:text>', methods=['POST'])\n",
    "def analyze_text(text):\n",
    "    if len(text) == 0:\n",
    "        return jsonify({'error': 'No text provided'}), 400\n",
    "    \n",
    "    doc = nlp(text) \n",
    "    person_count = len([ent.text for ent in doc.ents if ent.label_ == \"PERSON\"]) \n",
    "    topics = [token.text for token in doc if token.is_alpha and not token.is_stop]\n",
    "\n",
    "    name = request.form['name']\n",
    "    file = request.files['file']\n",
    "\n",
    "    directory_path = os.path.join('uploads', name) \n",
    "    filesname, extension = os.path.splitext(file.filename)\n",
    "    text_path = os.path.join(directory_path, \"{}.txt\".format(filesname))  \n",
    "\n",
    "    with open(text_path, 'a') as fil:\n",
    "        fil.write(\"\\nPerson Count: {}\\n\".format(str(person_count + 1)))\n",
    "   \n",
    "    return jsonify({'person_count' : person_count + 1 , 'topic' : topics[0], 'topic2' : topics[1]})\n",
    "\n",
    "@app.route('/api/convert-video-to-mp3', methods=['POST'])\n",
    "def convert_video_to_mp3():\n",
    "    if 'file' not in request.files:\n",
    "        return jsonify({'error': 'No file provided'}), 400\n",
    "\n",
    "    video_file = request.files['file']\n",
    "    name = request.form['name']\n",
    "\n",
    "    if video_file.filename == '':\n",
    "        return jsonify({'error': 'No selected file'}), 400\n",
    "\n",
    "    if video_file: \n",
    "        try:  \n",
    "            print(video_file.filename)\n",
    "            directory_path = os.path.join('uploads', name)\n",
    "            os.makedirs(directory_path, exist_ok=True) \n",
    "            video_path = os.path.join(directory_path, video_file.filename) \n",
    "            filesname, extension = os.path.splitext(video_file.filename)\n",
    "            audio_path = os.path.join(directory_path, \"{}.mp3\".format(filesname)) \n",
    "            video_file.save(video_path)\n",
    "            video_clip = VideoFileClip(video_path)\n",
    "            audio_clip = video_clip.audio\n",
    "            audio_clip.write_audiofile(audio_path)\n",
    "            audio_clip.close()\n",
    "            video_clip.close()\n",
    "\n",
    "            return jsonify({'message': 'Video converted to MP3 successfully', 'audio_file': audio_path}), 200\n",
    "        except Exception as e:\n",
    "            return jsonify({'error': 'Conversion error', 'details': str(e)}), 500\n",
    "\n",
    "def get_audio_length(audio_filename):\n",
    "    audio = AudioSegment.from_file(audio_filename)\n",
    "    return len(audio) / 1000  # Return length in seconds    \n",
    "\n",
    "def split_audio(input_audio, output_dir, segment_length_ms=60000):\n",
    "    print(\"Proccessing Input........\") \n",
    "    audio = AudioSegment.from_file(input_audio) \n",
    "    total_length_ms = len(audio) \n",
    "    num_segments = total_length_ms // segment_length_ms \n",
    "\n",
    "    for i in range(num_segments):\n",
    "        start_time = i * segment_length_ms\n",
    "        end_time = (i + 1) * segment_length_ms\n",
    "        segment = audio[start_time:end_time] \n",
    "        segment.export(os.path.join(output_dir, f\"segment_{i}.wav\"), format=\"wav\")\n",
    "        \n",
    "    if total_length_ms % segment_length_ms > 0:\n",
    "        start_time = num_segments * segment_length_ms\n",
    "        end_time = total_length_ms\n",
    "        last_segment = audio[start_time:end_time]\n",
    "        last_segment.export(os.path.join(output_dir, f\"segment_{num_segments}.wav\"), format=\"wav\")\n",
    "\n",
    "def transcribe_audio_segments(segment_dir, lan):\n",
    "    print(\"Converting to text........\")\n",
    "    recognizer = sr.Recognizer()\n",
    "    \n",
    "    transcribed_texts = []\n",
    "    \n",
    "    for filename in os.listdir(segment_dir): \n",
    "        audio_file = os.path.join(segment_dir, filename)\n",
    "        \n",
    "        with sr.AudioFile(audio_file) as source:\n",
    "            audio_text = recognizer.record(source)\n",
    "            text = recognizer.recognize_google(audio_text, language=lan)\n",
    "            transcribed_texts.append(text) \n",
    "\n",
    "    return transcribed_texts\n",
    "\n",
    "def join_transcribed_texts(texts):\n",
    "    return \" \".join(texts)\n",
    "\n",
    "def convert_mp3_to_wav(mp3_filename):\n",
    "    wav_filename = mp3_filename.replace('.mp3', '.wav')\n",
    "    audio = AudioSegment.from_mp3(mp3_filename)\n",
    "    audio.export(wav_filename, format=\"wav\")\n",
    "    return wav_filename\n",
    "\n",
    "@app.route('/api/convert-mp3-to-text', methods=['POST'])\n",
    "def convert_mp3_to_text():\n",
    "    if 'file' not in request.files:\n",
    "        return jsonify({'error': 'No file part'}), 400\n",
    "\n",
    "    file = request.files['file']\n",
    "    language = request.form['language']\n",
    "    name = request.form['name']\n",
    "    \n",
    "    if file.filename == '':\n",
    "        return jsonify({'error': 'No selected file'}), 400\n",
    "\n",
    "    if file:  \n",
    "        directory_path = os.path.join('uploads', name)\n",
    "        os.makedirs(directory_path, exist_ok=True) \n",
    "        mp3_filename = os.path.join(directory_path, file.filename)\n",
    "\n",
    "        file.save(mp3_filename) \n",
    "        segment_dir = 'segments'  \n",
    "        os.makedirs(segment_dir, exist_ok=True)\n",
    "        audio_length = get_audio_length(mp3_filename)\n",
    "\n",
    "        audio_file = open(mp3_filename, \"rb\")\n",
    "        transcript = client.audio.transcriptions.create(\n",
    "            file=audio_file,\n",
    "            model=\"whisper-1\",\n",
    "            response_format=\"verbose_json\",\n",
    "            timestamp_granularities=[\"word\"]\n",
    "        ) \n",
    "\n",
    "        filesname, extension = os.path.splitext(file.filename)\n",
    "        text_path = os.path.join(directory_path, \"{}.txt\".format(filesname)) \n",
    "\n",
    "        with open(text_path, 'w') as fil:\n",
    "            fil.write(\"Converted Text: \" + transcript.text + \"\\n\")\n",
    "\n",
    "        ######### ADDING TIMESTAMPS TO THE CONVERTED TEXT ############\n",
    "        current_time = 0\n",
    "        text_string = \"\"\n",
    "        \n",
    "        for index in range(len(transcript.words)):\n",
    "            word = transcript.words[index]['word']\n",
    "            start_time = transcript.words[index]['start']\n",
    "            \n",
    "            if index % 10 == 0:\n",
    "                minutes = int(current_time / 60)\n",
    "                seconds = round(current_time % 60, 1)\n",
    "                timestamp = f\"[{minutes}:{seconds}]\"\n",
    "                text_string += \" \" + timestamp\n",
    "            \n",
    "            text_string += \" \" + word \n",
    "            current_time = start_time\n",
    "\n",
    "        minutes = int(current_time / 60)\n",
    "        seconds = round(current_time % 60, 1)\n",
    "        final_timestamp = f\"[{minutes}:{seconds}]\"\n",
    "        text_string += \" \" + final_timestamp\n",
    " \n",
    "        return jsonify({'text': text_string, 'simple_text': transcript.text})\n",
    "\n",
    "@app.route('/api/convert-mp4-to-text', methods=['POST'])\n",
    "def convert_mp4_to_text():\n",
    "    language = request.form['language']\n",
    "    file = request.files['file']\n",
    "    name = request.form['name']\n",
    "\n",
    "    filesname, extension = os.path.splitext(file.filename)\n",
    "    directory_path = os.path.join('uploads', name)\n",
    "    os.makedirs(directory_path, exist_ok=True)  \n",
    "\n",
    "    file = os.path.abspath('./uploads/{}/{}.mp3'.format(name, filesname)) \n",
    "\n",
    "    if file: \n",
    "        mp3_filename = file\n",
    "        wav_filename = mp3_filename.replace('.mp3', '.wav') \n",
    "        AudioSegment.from_mp3(mp3_filename).export(wav_filename, format=\"wav\")\n",
    "\n",
    "    segment_dir = 'segments'\n",
    "    try:\n",
    "        if not os.path.exists(segment_dir):\n",
    "            os.mkdir(segment_dir)\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating directory: {e}\")\n",
    "\n",
    "    audio_length = get_audio_length(mp3_filename)\n",
    "\n",
    "    audio_file = open(mp3_filename, \"rb\")\n",
    "    transcript = client.audio.transcriptions.create(\n",
    "            file=audio_file,\n",
    "            model=\"whisper-1\",\n",
    "            response_format=\"verbose_json\",\n",
    "            timestamp_granularities=[\"word\"]\n",
    "        ) \n",
    " \n",
    "    text_path = os.path.join(directory_path, \"{}.txt\".format(filesname)) \n",
    "\n",
    "    with open(text_path, 'w') as fil:\n",
    "        fil.write(\"Converted Text: \" + transcript.text + \"\\n\")\n",
    "\n",
    "    ######### ADDING TIMESTAMPS TO THE CONVERTED TEXT ############\n",
    "    current_time = 0\n",
    "    text_string = \"\"\n",
    "    \n",
    "    for index in range(len(transcript.words)):\n",
    "        word = transcript.words[index]['word']\n",
    "        start_time = transcript.words[index]['start']\n",
    "        \n",
    "        if index % 10 == 0:\n",
    "            minutes = int(current_time / 60)\n",
    "            seconds = round(current_time % 60, 1)\n",
    "            timestamp = f\"[{minutes}:{seconds}]\"\n",
    "            text_string += \" \" + timestamp\n",
    "        \n",
    "        text_string += \" \" + word \n",
    "        current_time = start_time\n",
    "\n",
    "    minutes = int(current_time / 60)\n",
    "    seconds = round(current_time % 60, 1)\n",
    "    final_timestamp = f\"[{minutes}:{seconds}]\"\n",
    "    text_string += \" \" + final_timestamp\n",
    "\n",
    "    directory_path = os.path.join('uploads', name)\n",
    "    text_path = os.path.join(directory_path, \"{}.txt\".format(filesname)) \n",
    "\n",
    "    with open(text_path, 'w') as fil:\n",
    "        fil.write(\"Converted Text: \" + transcript.text + \"\\n\")\n",
    "\n",
    "    return jsonify({'text': text_string, 'simple_text': transcript.text})\n",
    "\n",
    "\n",
    "@app.route('/api/translate_toar/<string:text>', methods=['GET'], endpoint='translate_to_ar')\n",
    "def translate_to_ar(text):    \n",
    "    translator = Translator() \n",
    "    arabic_translation = translator.translate(text,  src='auto', dest='ar').text\n",
    "    return jsonify({'translated_txt': arabic_translation})\n",
    "\n",
    "@app.route('/api/translate_totr/<string:text>', methods=['GET'], endpoint='translate_to_tr')\n",
    "def translate_to_tr(text):  \n",
    "    translator = Translator()    \n",
    "\n",
    "    turkish_translation = translator.translate(text, src='auto', dest='tr').text\n",
    "    return jsonify({'translated_txt': turkish_translation})\n",
    "\n",
    "@app.route('/api/translate_toen/<string:text>', methods=['GET'], endpoint='translate_to_en')\n",
    "def translate_to_en(text):  \n",
    "    translator = Translator()    \n",
    "\n",
    "    english_translation = translator.translate(text, src='auto', dest='en').text\n",
    "    return jsonify({'translated_txt': english_translation})\n",
    "\n",
    "@app.route('/api/translate_tohi/<string:text>', methods=['GET'], endpoint='translate_to_hi')\n",
    "def translate_to_hi(text):  \n",
    "    translator = Translator()    \n",
    "\n",
    "    hindi_translation = translator.translate(text, src='auto', dest='hi').text\n",
    "    return jsonify({'translated_txt': hindi_translation})\n",
    "\n",
    "def add_newlines_every_n_words(input_string, n=10):\n",
    "    words = input_string.split()\n",
    "    output_string = ''\n",
    "    for i, word in enumerate(words):\n",
    "        if i > 0 and i % n == 0:\n",
    "            output_string += '\\n'\n",
    "        output_string += word + ' '\n",
    "    return output_string.strip()\n",
    "\n",
    "def remove_punctuation(sentence): \n",
    "    translator = str.maketrans('', '', string.punctuation) \n",
    "    cleaned_sentence = sentence.translate(translator)\n",
    "    return cleaned_sentence\n",
    "\n",
    "@app.route('/api/findtopic/<string:text>', methods=['POST'])\n",
    "def topic_finder(text):\n",
    "    name = request.form['name']\n",
    "    file = request.files['file']\n",
    "\n",
    "    cleaned_text = remove_punctuation(text)\n",
    "    words_list_next = cleaned_text.split() \n",
    "    if len(words_list_next)<450:\n",
    "        selected_string = words_list_next\n",
    "    else:\n",
    "        selected_words = words_list_next[:450]\n",
    "        selected_string = ' '.join(selected_words)\n",
    "\n",
    "    pipe = pipeline(\"text-classification\", model=\"unitary/toxic-bert\")\n",
    "    pipe2 = pipeline(\"summarization\", model=\"google/pegasus-xsum\")\n",
    "\n",
    "    topic = pipe(selected_string)  \n",
    "    topic = topic[0]['label']\n",
    "\n",
    "    topic2 = pipe2(selected_string, max_length = 20)\n",
    "    topic2 = topic2[0]['summary_text']\n",
    "\n",
    "    directory_path = os.path.join('uploads', name) \n",
    "    filesname, extension = os.path.splitext(file.filename)\n",
    "    text_path = os.path.join(directory_path, \"{}.txt\".format(filesname))  \n",
    "\n",
    "    with open(text_path, 'a') as fil:\n",
    "        fil.write(\"\\nTopic: {}\\n\".format(topic2))\n",
    "    \n",
    "    return jsonify({'topic': topic, 'topic2': topic2})\n",
    "\n",
    "@app.route('/api/findSummary', methods=['POST'])\n",
    "def summary_find():\n",
    "    text = request.form['text']\n",
    "    pipe = pipeline(\"summarization\", model=\"google/pegasus-xsum\")\n",
    "    \n",
    "    #temp = add_newlines_every_n_words(text, 30)\n",
    "    try: \n",
    "        summary = summarize(text)\n",
    "        print(\"len: \", len(summary))\n",
    "    except:\n",
    "        print(\"Error in summarization using gensim\") \n",
    "        summary = \"\"\n",
    "\n",
    "    if len(summary) == 0:\n",
    "        output = pipe(text) \n",
    "        summary = output[0]['summary_text']\n",
    "             \n",
    "    translator = Translator() \n",
    "    arabic_summary = translator.translate(summary, src='en', dest='ar').text\n",
    "    turkish_summary = translator.translate(summary, src='en', dest='tr').text\n",
    "\n",
    "    name = request.form['name']\n",
    "    file = request.files['file']\n",
    "\n",
    "    directory_path = os.path.join('uploads', name) \n",
    "    filesname, extension = os.path.splitext(file.filename)\n",
    "    text_path = os.path.join(directory_path, \"{}.txt\".format(filesname))  \n",
    "\n",
    "    with open(text_path, 'a') as fil:\n",
    "        fil.write(\"\\nSummary: {}\\n\".format(str(summary)))\n",
    "\n",
    "    return jsonify({'summary_en': str(summary), 'summary_ar': arabic_summary, 'summary_tr': turkish_summary})\n",
    "\n",
    "@app.route('/api/sentiment/<string:text>', methods=['POST'])\n",
    "def sentiment(text):\n",
    "    name = request.form['name']\n",
    "    file = request.files['file']\n",
    "\n",
    "    nltk.download('vader_lexicon')\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    scores = analyzer.polarity_scores(text)\n",
    "    positive_percent = round(scores['pos'] * 100, 2)\n",
    "    negative_percent = round(scores['neg'] * 100, 2)\n",
    "\n",
    "    total = positive_percent + negative_percent\n",
    "    fin_pos = round((positive_percent/total)*100, 2)\n",
    "    fin_neg = round((negative_percent/total)*100, 2) \n",
    "\n",
    "    directory_path = os.path.join('uploads', name) \n",
    "    filesname, extension = os.path.splitext(file.filename)\n",
    "    text_path = os.path.join(directory_path, \"{}.txt\".format(filesname))  \n",
    "\n",
    "    with open(text_path, 'a') as fil:\n",
    "        fil.write(\"\\nPositive Sentiment: {}% \\nNegative Sentiment: {}%\".format(fin_pos, fin_neg))\n",
    "\n",
    "    return jsonify({'positive': fin_pos, 'negative': fin_neg})\n",
    "\n",
    "if __name__ == '__main__': \n",
    "    app.run(debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

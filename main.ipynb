{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bert base model approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)lve/main/config.json: 100%|██████████| 570/570 [00:00<?, ?B/s] \n",
      "Downloading model.safetensors: 100%|██████████| 440M/440M [03:06<00:00, 2.36MB/s] \n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.weight', 'cls.seq_relationship.weight', 'bert.pooler.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 28.0/28.0 [00:00<?, ?B/s]\n",
      "Downloading (…)solve/main/vocab.txt: 100%|██████████| 232k/232k [00:01<00:00, 132kB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|██████████| 466k/466k [00:01<00:00, 387kB/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"fill-mask\", model=\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pipe(\"Finance is a fundamental pillar of the modern global economy, governing the allocation and management of funds. It encompasses a vast spectrum of activities, from personal financial planning to intricate investment strategies for multinational corporations. At its core, finance revolves around the efficient utilization of monetary resources, striving to maximize value and mitigate risk.In the realm of personal finance, individuals make decisions about saving, investing, budgeting, and debt management to secure their financial well-being. Sound financial planning empowers individuals to achieve their life goals, whether it be buying a home, funding education, or planning for retirement. In the corporate world, finance plays a pivotal role in driving growth and sustainability. It involves capital budgeting, risk assessment, and the allocation of resources to various projects. Financial markets, both traditional and digital, enable companies to raise capital and manage liquidity efficiently. In an era of rapid technological advancements, finance has seen an evolution through digitalization and fintech innovations. Mobile banking, cryptocurrencies, and peer-to-peer lending platforms are reshaping the financial landscape, offering greater accessibility and efficiency. Finance, at its heart, is a balancing act between risk and reward. It influences our daily lives, guides corporate strategies, and shapes the global economy. Understanding the principles of finance empowers individuals and organizations to make informed decisions and navigate the intricate world of money, investments, and financial well-being [MASK]\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flask App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./uploads\\final.mp4\n",
      "MoviePy - Writing audio in c:\\Audio_Analysis_UI_UX\\uploads\\output.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [19/Oct/2023 00:10:49] \"POST /api/convert-video-to-mp3 HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [19/Oct/2023 00:10:52] \"OPTIONS /api/convert-mp4-to-text HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Oct/2023 00:11:32] \"POST /api/convert-mp4-to-text HTTP/1.1\" 200 -\n",
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-xsum and are newly initialized: ['model.encoder.embed_positions.weight', 'model.decoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Your max_length is set to 100, but your input_length is only 32. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=16)\n",
      "127.0.0.1 - - [19/Oct/2023 00:11:45] \"GET /api/findtopic/why%20I%20was%20elements%20I%20love%20that%20I%20don't%20have%20to%20enemy%20my%20own%20text%20in%20conversations%20in%20After%20Effects%20that's%20a%20lot%20of%20pictures%20unlimited%20download HTTP/1.1\" 200 -\n",
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-xsum and are newly initialized: ['model.encoder.embed_positions.weight', 'model.decoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Your max_length is set to 200, but your input_length is only 32. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=16)\n",
      "127.0.0.1 - - [19/Oct/2023 00:12:07] \"GET /api/findSummary/why%20I%20was%20elements%20I%20love%20that%20I%20don't%20have%20to%20enemy%20my%20own%20text%20in%20conversations%20in%20After%20Effects%20that's%20a%20lot%20of%20pictures%20unlimited%20download HTTP/1.1\" 200 -\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\haris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "127.0.0.1 - - [19/Oct/2023 00:12:08] \"GET /api/sentiment/why%20I%20was%20elements%20I%20love%20that%20I%20don't%20have%20to%20enemy%20my%20own%20text%20in%20conversations%20in%20After%20Effects%20that's%20a%20lot%20of%20pictures%20unlimited%20download HTTP/1.1\" 200 -\n",
      "[2023-10-19 00:12:20,508] ERROR in app: Exception on /api/translate_totr/why I was elements I love that I don't have to enemy my own text in conversations in After Effects that's a lot of pictures unlimited download [GET]\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\flask\\app.py\", line 1455, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\flask\\app.py\", line 869, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\flask_cors\\extension.py\", line 176, in wrapped_function\n",
      "    return cors_after_request(app.make_response(f(*args, **kwargs)))\n",
      "                                                ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\flask\\app.py\", line 867, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\flask\\app.py\", line 852, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\haris\\AppData\\Local\\Temp\\ipykernel_18596\\1181687485.py\", line 121, in translate_to_tr\n",
      "    turkish_translation = translator.translate(text, src='en', dest='tr').text\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\googletrans\\client.py\", line 194, in translate\n",
      "    data, response = self._translate(text, dest, src)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\googletrans\\client.py\", line 120, in _translate\n",
      "    r = self.client.post(url, params=params, data=data)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\httpx\\_client.py\", line 824, in post\n",
      "    return self.request(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\httpx\\_client.py\", line 600, in request\n",
      "    return self.send(\n",
      "           ^^^^^^^^^^\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\httpx\\_client.py\", line 620, in send\n",
      "    response = self.send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\httpx\\_client.py\", line 647, in send_handling_redirects\n",
      "    response = self.send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\httpx\\_client.py\", line 684, in send_handling_auth\n",
      "    response = self.send_single_request(request, timeout)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\httpx\\_client.py\", line 714, in send_single_request\n",
      "    ) = transport.request(\n",
      "        ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py\", line 152, in request\n",
      "    response = connection.request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\httpcore\\_sync\\connection.py\", line 65, in request\n",
      "    self.socket = self._open_socket(timeout)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\httpcore\\_sync\\connection.py\", line 85, in _open_socket\n",
      "    return self.backend.open_tcp_stream(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\httpcore\\_backends\\sync.py\", line 133, in open_tcp_stream\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\contextlib.py\", line 155, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\httpcore\\_exceptions.py\", line 12, in map_exceptions\n",
      "    raise to_exc(exc) from None\n",
      "httpcore._exceptions.ConnectTimeout: timed out\n",
      "127.0.0.1 - - [19/Oct/2023 00:12:20] \"GET /api/translate_totr/why%20I%20was%20elements%20I%20love%20that%20I%20don't%20have%20to%20enemy%20my%20own%20text%20in%20conversations%20in%20After%20Effects%20that's%20a%20lot%20of%20pictures%20unlimited%20download HTTP/1.1\" 500 -\n",
      "127.0.0.1 - - [19/Oct/2023 00:12:23] \"GET /api/translate_toar/why%20I%20was%20elements%20I%20love%20that%20I%20don't%20have%20to%20enemy%20my%20own%20text%20in%20conversations%20in%20After%20Effects%20that's%20a%20lot%20of%20pictures%20unlimited%20download HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Oct/2023 00:12:28] \"GET /api/translate_totr/why%20I%20was%20elements%20I%20love%20that%20I%20don't%20have%20to%20enemy%20my%20own%20text%20in%20conversations%20in%20After%20Effects%20that's%20a%20lot%20of%20pictures%20unlimited%20download HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Oct/2023 00:19:31] \"POST /api/convert-mp3-to-text HTTP/1.1\" 500 -\n",
      "127.0.0.1 - - [19/Oct/2023 00:20:03] \"POST /api/convert-mp3-to-text HTTP/1.1\" 200 -\n",
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-xsum and are newly initialized: ['model.encoder.embed_positions.weight', 'model.decoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Your max_length is set to 100, but your input_length is only 21. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=10)\n",
      "127.0.0.1 - - [19/Oct/2023 00:20:21] \"GET /api/findtopic/American%20accent%20in%2010%20seconds%20is%20it%20is%20saying%20is%20he%20nice%20say%20easy%20nice%20easy%20nice%20easy%20nice%20nice HTTP/1.1\" 200 -\n",
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-xsum and are newly initialized: ['model.encoder.embed_positions.weight', 'model.decoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Your max_length is set to 200, but your input_length is only 21. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=10)\n",
      "127.0.0.1 - - [19/Oct/2023 00:20:41] \"GET /api/findSummary/American%20accent%20in%2010%20seconds%20is%20it%20is%20saying%20is%20he%20nice%20say%20easy%20nice%20easy%20nice%20easy%20nice%20nice HTTP/1.1\" 200 -\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\haris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "127.0.0.1 - - [19/Oct/2023 00:20:42] \"GET /api/sentiment/American%20accent%20in%2010%20seconds%20is%20it%20is%20saying%20is%20he%20nice%20say%20easy%20nice%20easy%20nice%20easy%20nice%20nice HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Oct/2023 00:20:48] \"POST /api/convert-mp3-to-text HTTP/1.1\" 200 -\n",
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-xsum and are newly initialized: ['model.encoder.embed_positions.weight', 'model.decoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Your max_length is set to 100, but your input_length is only 21. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=10)\n",
      "127.0.0.1 - - [19/Oct/2023 00:21:07] \"GET /api/findtopic/American%20accent%20in%2010%20seconds%20is%20it%20is%20saying%20is%20he%20nice%20say%20easy%20nice%20easy%20nice%20easy%20nice%20nice HTTP/1.1\" 200 -\n",
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-xsum and are newly initialized: ['model.encoder.embed_positions.weight', 'model.decoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Your max_length is set to 200, but your input_length is only 21. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=10)\n",
      "127.0.0.1 - - [19/Oct/2023 00:21:27] \"GET /api/findSummary/American%20accent%20in%2010%20seconds%20is%20it%20is%20saying%20is%20he%20nice%20say%20easy%20nice%20easy%20nice%20easy%20nice%20nice HTTP/1.1\" 200 -\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\haris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "127.0.0.1 - - [19/Oct/2023 00:21:28] \"GET /api/sentiment/American%20accent%20in%2010%20seconds%20is%20it%20is%20saying%20is%20he%20nice%20say%20easy%20nice%20easy%20nice%20easy%20nice%20nice HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Oct/2023 00:21:34] \"GET /api/translate_toar/American%20accent%20in%2010%20seconds%20is%20it%20is%20saying%20is%20he%20nice%20say%20easy%20nice%20easy%20nice%20easy%20nice%20nice HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Oct/2023 00:21:39] \"GET /api/translate_totr/American%20accent%20in%2010%20seconds%20is%20it%20is%20saying%20is%20he%20nice%20say%20easy%20nice%20easy%20nice%20easy%20nice%20nice HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import speech_recognition as sr\n",
    "import pydub\n",
    "from googletrans import Translator\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModelForSeq2SeqLM\n",
    "from google.cloud import speech\n",
    "import subprocess\n",
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "import os\n",
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "from pydub import AudioSegment \n",
    "import speech_recognition as sr \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from googletrans import Translator  \n",
    "from transformers import pipeline\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app, origins=\"http://localhost:3000\", supports_credentials=True)\n",
    "\n",
    "@app.route('/api/convert-video-to-mp3', methods=['POST'])\n",
    "def convert_video_to_mp3():\n",
    "    if 'file' not in request.files:\n",
    "        return jsonify({'error': 'No file provided'}), 400\n",
    "\n",
    "    video_file = request.files['file']\n",
    "    if video_file.filename == '':\n",
    "        return jsonify({'error': 'No selected file'}), 400\n",
    "\n",
    "    if video_file: \n",
    "        try: \n",
    "            video_path = os.path.join('./uploads', video_file.filename)  \n",
    "            print(video_path)\n",
    "            video_file.save(video_path)\n",
    " \n",
    "            audio_path = os.path.abspath('./uploads/output.mp3') \n",
    "            video_clip = VideoFileClip(video_path)\n",
    "            audio_clip = video_clip.audio\n",
    "            audio_clip.write_audiofile(audio_path)\n",
    "            audio_clip.close()\n",
    "            video_clip.close()\n",
    "\n",
    "            return jsonify({'message': 'Video converted to MP3 successfully', 'audio_file': audio_path}), 200\n",
    "        except Exception as e:\n",
    "            return jsonify({'error': 'Conversion error', 'details': str(e)}), 500\n",
    "        \n",
    "\n",
    "@app.route('/api/convert-mp3-to-text', methods=['POST'])\n",
    "def convert_mp3_to_text():\n",
    "    if 'file' not in request.files:\n",
    "        return jsonify({'error': 'No file part'}), 400\n",
    "\n",
    "    file = request.files['file']\n",
    "    if file.filename == '':\n",
    "        return jsonify({'error': 'No selected file'}), 400\n",
    "\n",
    "    if file: \n",
    "        mp3_filename = os.path.join('uploads', file.filename)\n",
    "        file.save(mp3_filename)\n",
    " \n",
    "        wav_filename = mp3_filename.replace('.mp3', '.wav')\n",
    "        AudioSegment.from_mp3(mp3_filename).export(wav_filename, format=\"wav\")\n",
    " \n",
    "        recognizer = sr.Recognizer()\n",
    "        with sr.AudioFile(wav_filename) as source:\n",
    "            audio = recognizer.record(source)\n",
    "\n",
    "        try:\n",
    "            text = recognizer.recognize_google(audio)\n",
    "            return jsonify({'text': text})\n",
    "        except sr.UnknownValueError:\n",
    "            return jsonify({'error': 'Could not understand audio'}), 400\n",
    "        except sr.RequestError as e:\n",
    "            return jsonify({'error': f'Speech Recognition error: {e}'}), 500\n",
    "        \n",
    "\n",
    "@app.route('/api/convert-mp4-to-text', methods=['POST'])\n",
    "def convert_mp4_to_text():\n",
    "    file = os.path.abspath('./uploads/output.mp3') \n",
    "\n",
    "    if file: \n",
    "        mp3_filename = file\n",
    "        wav_filename = mp3_filename.replace('.mp3', '.wav') \n",
    "        AudioSegment.from_mp3(mp3_filename).export(wav_filename, format=\"wav\")\n",
    " \n",
    "        recognizer = sr.Recognizer()\n",
    "        with sr.AudioFile(wav_filename) as source:\n",
    "            audio = recognizer.record(source)\n",
    "\n",
    "        try:\n",
    "            text = recognizer.recognize_google(audio)\n",
    "            return jsonify({'text': text})\n",
    "        except sr.UnknownValueError:\n",
    "            return jsonify({'error': 'Could not understand audio'}), 400\n",
    "        except sr.RequestError as e:\n",
    "            return jsonify({'error': f'Speech Recognition error: {e}'}), 500\n",
    "        \n",
    "\n",
    "@app.route('/api/translate_toar/<string:text>', methods=['GET'])\n",
    "def translate_to_ar(text):    \n",
    "    translator = Translator() \n",
    "    arabic_translation = translator.translate(text, src='en', dest='ar').text\n",
    "    return jsonify({'translated_txt': arabic_translation})\n",
    "\n",
    "\n",
    "@app.route('/api/translate_totr/<string:text>', methods=['GET'])\n",
    "def translate_to_tr(text):  \n",
    "    translator = Translator()    \n",
    "    turkish_translation = translator.translate(text, src='en', dest='tr').text\n",
    "    return jsonify({'translated_txt': turkish_translation})\n",
    "\n",
    "@app.route('/api/findtopic/<string:text>', methods=['GET'])\n",
    "def topic_finder(text):\n",
    "    pipe = pipeline(\"summarization\", model=\"google/pegasus-xsum\")\n",
    "    topic = pipe(text, max_length = 100)\n",
    "    topic = topic[0]['summary_text']\n",
    "    return jsonify({'topic': topic})\n",
    "\n",
    "@app.route('/api/findSummary/<string:text>', methods=['GET'])\n",
    "def summary_find(text):\n",
    "    pipe = pipeline(\"summarization\", model=\"google/pegasus-xsum\")\n",
    "    output = pipe(text, max_length = 200)\n",
    "    final_summary = output[0]['summary_text']\n",
    "\n",
    "    translator = Translator() \n",
    "    arabic_summary = translator.translate(final_summary, src='en', dest='ar').text\n",
    "    turkish_summary = translator.translate(final_summary, src='en', dest='tr').text\n",
    "\n",
    "    return jsonify({'summary_en': final_summary, 'summary_ar': arabic_summary, 'summary_tr': turkish_summary})\n",
    "\n",
    "\n",
    "@app.route('/api/sentiment/<string:text>', methods=['GET'])\n",
    "def sentiment(text):\n",
    "    nltk.download('vader_lexicon')\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    scores = analyzer.polarity_scores(text)\n",
    "    positive_percent = round(scores['pos'] * 100, 2)\n",
    "    negative_percent = round(scores['neg'] * 100, 2)\n",
    "\n",
    "    return jsonify({'positive': positive_percent, 'negative': negative_percent})\n",
    "\n",
    "if __name__ == '__main__': \n",
    "    app.run(debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

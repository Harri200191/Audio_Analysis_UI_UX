{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./uploads\\final.mp4\n",
      "MoviePy - Writing audio in c:\\Audio_Analysis_UI_UX\\uploads\\output.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [12/Nov/2023 23:26:16] \"POST /api/convert-video-to-mp3 HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [12/Nov/2023 23:26:19] \"OPTIONS /api/convert-mp4-to-text HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proccessing Input........\n",
      "Converting to text........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [12/Nov/2023 23:26:40] \"POST /api/convert-mp4-to-text HTTP/1.1\" 200 -\n",
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-xsum and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Your max_length is set to 100, but your input_length is only 32. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=16)\n",
      "127.0.0.1 - - [12/Nov/2023 23:26:52] \"GET /api/findtopic/why%20I%20was%20elements%20I%20love%20that%20I%20don't%20have%20to%20enemy%20my%20own%20text%20in%20conversations%20in%20After%20Effects%20that's%20a%20lot%20of%20pictures%20unlimited%20download HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [12/Nov/2023 23:26:53] \"GET /api/analyze-audio/why%20I%20was%20elements%20I%20love%20that%20I%20don't%20have%20to%20enemy%20my%20own%20text%20in%20conversations%20in%20After%20Effects%20that's%20a%20lot%20of%20pictures%20unlimited%20download HTTP/1.1\" 200 -\n",
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-xsum and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Your max_length is set to 200, but your input_length is only 32. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=16)\n",
      "127.0.0.1 - - [12/Nov/2023 23:27:11] \"GET /api/findSummary/why%20I%20was%20elements%20I%20love%20that%20I%20don't%20have%20to%20enemy%20my%20own%20text%20in%20conversations%20in%20After%20Effects%20that's%20a%20lot%20of%20pictures%20unlimited%20download HTTP/1.1\" 200 -\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\haris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "127.0.0.1 - - [12/Nov/2023 23:27:13] \"GET /api/sentiment/why%20I%20was%20elements%20I%20love%20that%20I%20don't%20have%20to%20enemy%20my%20own%20text%20in%20conversations%20in%20After%20Effects%20that's%20a%20lot%20of%20pictures%20unlimited%20download HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./uploads\\final.mp4\n",
      "MoviePy - Writing audio in c:\\Audio_Analysis_UI_UX\\uploads\\output.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [12/Nov/2023 23:28:13] \"POST /api/convert-video-to-mp3 HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [12/Nov/2023 23:28:16] \"OPTIONS /api/convert-mp4-to-text HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proccessing Input........\n",
      "Converting to text........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [12/Nov/2023 23:28:36] \"POST /api/convert-mp4-to-text HTTP/1.1\" 200 -\n",
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-xsum and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Your max_length is set to 100, but your input_length is only 32. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=16)\n",
      "127.0.0.1 - - [12/Nov/2023 23:28:56] \"GET /api/findtopic/why%20I%20was%20elements%20I%20love%20that%20I%20don't%20have%20to%20enemy%20my%20own%20text%20in%20conversations%20in%20After%20Effects%20that's%20a%20lot%20of%20pictures%20unlimited%20download HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [12/Nov/2023 23:28:57] \"GET /api/analyze-audio/why%20I%20was%20elements%20I%20love%20that%20I%20don't%20have%20to%20enemy%20my%20own%20text%20in%20conversations%20in%20After%20Effects%20that's%20a%20lot%20of%20pictures%20unlimited%20download HTTP/1.1\" 200 -\n",
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-xsum and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Your max_length is set to 200, but your input_length is only 32. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=16)\n",
      "127.0.0.1 - - [12/Nov/2023 23:29:21] \"GET /api/findSummary/why%20I%20was%20elements%20I%20love%20that%20I%20don't%20have%20to%20enemy%20my%20own%20text%20in%20conversations%20in%20After%20Effects%20that's%20a%20lot%20of%20pictures%20unlimited%20download HTTP/1.1\" 200 -\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\haris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "127.0.0.1 - - [12/Nov/2023 23:29:22] \"GET /api/sentiment/why%20I%20was%20elements%20I%20love%20that%20I%20don't%20have%20to%20enemy%20my%20own%20text%20in%20conversations%20in%20After%20Effects%20that's%20a%20lot%20of%20pictures%20unlimited%20download HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [12/Nov/2023 23:29:34] \"GET /api/translate_totr/why%20I%20was%20elements%20I%20love%20that%20I%20don't%20have%20to%20enemy%20my%20own%20text%20in%20conversations%20in%20After%20Effects%20that's%20a%20lot%20of%20pictures%20unlimited%20download HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [12/Nov/2023 23:29:37] \"GET /api/translate_toar/why%20I%20was%20elements%20I%20love%20that%20I%20don't%20have%20to%20enemy%20my%20own%20text%20in%20conversations%20in%20After%20Effects%20that's%20a%20lot%20of%20pictures%20unlimited%20download HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import speech_recognition as sr \n",
    "from googletrans import Translator\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModelForSeq2SeqLM\n",
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "from pydub import AudioSegment  \n",
    "from transformers import pipeline\n",
    "import spacy\n",
    "import moviepy.editor as mp \n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app, origins=\"http://localhost:3000\", supports_credentials=True)\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "@app.route('/api/analyze-audio/<string:text>', methods=['GET'])\n",
    "def analyze_text(text):\n",
    "    doc = nlp(text) \n",
    "    person_count = len([ent.text for ent in doc.ents if ent.label_ == \"PERSON\"]) \n",
    "    topics = [token.text for token in doc if token.is_alpha and not token.is_stop]\n",
    "    \n",
    "    return jsonify({'person_count' : person_count + 1 , 'topic' : topics[0]})\n",
    " \n",
    "\n",
    "@app.route('/api/convert-video-to-mp3', methods=['POST'])\n",
    "def convert_video_to_mp3():\n",
    "    if 'file' not in request.files:\n",
    "        return jsonify({'error': 'No file provided'}), 400\n",
    "\n",
    "    video_file = request.files['file']\n",
    "    if video_file.filename == '':\n",
    "        return jsonify({'error': 'No selected file'}), 400\n",
    "\n",
    "    if video_file: \n",
    "        try: \n",
    "            video_path = os.path.join('./uploads', video_file.filename)  \n",
    "            print(video_path)\n",
    "            video_file.save(video_path)\n",
    " \n",
    "            audio_path = os.path.abspath('./uploads/output.mp3') \n",
    "            video_clip = VideoFileClip(video_path)\n",
    "            audio_clip = video_clip.audio\n",
    "            audio_clip.write_audiofile(audio_path)\n",
    "            audio_clip.close()\n",
    "            video_clip.close()\n",
    "\n",
    "            return jsonify({'message': 'Video converted to MP3 successfully', 'audio_file': audio_path}), 200\n",
    "        except Exception as e:\n",
    "            return jsonify({'error': 'Conversion error', 'details': str(e)}), 500\n",
    "        \n",
    "def split_audio(input_audio, output_dir, segment_length_ms):\n",
    "    print(\"Proccessing Input........\") \n",
    "    audio = AudioSegment.from_file(input_audio) \n",
    "    total_length_ms = len(audio) \n",
    "    num_segments = total_length_ms // segment_length_ms \n",
    "\n",
    "    for i in range(num_segments):\n",
    "        start_time = i * segment_length_ms\n",
    "        end_time = (i + 1) * segment_length_ms\n",
    "        segment = audio[start_time:end_time] \n",
    "        segment.export(os.path.join(output_dir, f\"segment_{i}.wav\"), format=\"wav\")\n",
    "        \n",
    "    if total_length_ms % segment_length_ms > 0:\n",
    "        start_time = num_segments * segment_length_ms\n",
    "        end_time = total_length_ms\n",
    "        last_segment = audio[start_time:end_time]\n",
    "        last_segment.export(os.path.join(output_dir, f\"segment_{num_segments}.wav\"), format=\"wav\")\n",
    "\n",
    "def transcribe_audio_segments(segment_dir):\n",
    "    print(\"Converting to text........\")\n",
    "    recognizer = sr.Recognizer()\n",
    "    \n",
    "    transcribed_texts = []\n",
    "    \n",
    "    for filename in os.listdir(segment_dir):\n",
    "        if filename.endswith(\".wav\"):\n",
    "            audio_file = os.path.join(segment_dir, filename)\n",
    "            \n",
    "            with sr.AudioFile(audio_file) as source:\n",
    "                audio_text = recognizer.record(source)\n",
    "                text = recognizer.recognize_google(audio_text)\n",
    "                transcribed_texts.append(text)\n",
    "    \n",
    "    return transcribed_texts\n",
    "\n",
    "def join_transcribed_texts(texts):\n",
    "    return \" \".join(texts)\n",
    "\n",
    "\n",
    "@app.route('/api/convert-mp3-to-text', methods=['POST'])\n",
    "def convert_mp3_to_text():\n",
    "    if 'file' not in request.files:\n",
    "        return jsonify({'error': 'No file part'}), 400\n",
    "\n",
    "    file = request.files['file']\n",
    "    if file.filename == '':\n",
    "        return jsonify({'error': 'No selected file'}), 400\n",
    "\n",
    "    if file:\n",
    "        mp3_filename = os.path.join('uploads', file.filename)\n",
    "        file.save(mp3_filename)\n",
    "        segment_dir = 'segments'  \n",
    "        os.makedirs(segment_dir, exist_ok=True)\n",
    "        split_audio(mp3_filename, segment_dir, segment_length_ms=60000)\n",
    "        transcribed_texts = transcribe_audio_segments(segment_dir) \n",
    "        joined_text = join_transcribed_texts(transcribed_texts)\n",
    "\n",
    "        return jsonify({'text': joined_text})\n",
    "    \n",
    "\"\"\" def convert_mp3_to_text():\n",
    "    if 'file' not in request.files:\n",
    "        return jsonify({'error': 'No file part'}), 400\n",
    "\n",
    "    file = request.files['file']\n",
    "    if file.filename == '':\n",
    "        return jsonify({'error': 'No selected file'}), 400\n",
    "\n",
    "    if file: \n",
    "        mp3_filename = os.path.join('uploads', file.filename)\n",
    "        file.save(mp3_filename)\n",
    " \n",
    "        wav_filename = mp3_filename.replace('.mp3', '.wav')\n",
    "        AudioSegment.from_mp3(mp3_filename).export(wav_filename, format=\"wav\")\n",
    " \n",
    "        recognizer = sr.Recognizer()\n",
    "        with sr.AudioFile(wav_filename) as source:\n",
    "            audio = recognizer.record(source)\n",
    "\n",
    "        try:\n",
    "            text = recognizer.recognize_google(audio)\n",
    "            return jsonify({'text': text})\n",
    "        except sr.UnknownValueError:\n",
    "            return jsonify({'error': 'Could not understand audio'}), 400\n",
    "        except sr.RequestError as e:\n",
    "            return jsonify({'error': f'Speech Recognition error: {e}'}), 500 \"\"\"\n",
    "        \n",
    "\n",
    "\"\"\" @app.route('/api/convert-mp4-to-text', methods=['POST'])\n",
    "def convert_mp4_to_text():\n",
    "    file = os.path.abspath('./uploads/output.mp3') \n",
    "\n",
    "    if file: \n",
    "        mp3_filename = file\n",
    "        wav_filename = mp3_filename.replace('.mp3', '.wav') \n",
    "        AudioSegment.from_mp3(mp3_filename).export(wav_filename, format=\"wav\")\n",
    " \n",
    "        recognizer = sr.Recognizer()\n",
    "        with sr.AudioFile(wav_filename) as source:\n",
    "            audio = recognizer.record(source)\n",
    "\n",
    "        try:\n",
    "            text = recognizer.recognize_google(audio)\n",
    "            return jsonify({'text': text})\n",
    "        except sr.UnknownValueError:\n",
    "            return jsonify({'error': 'Could not understand audio'}), 400\n",
    "        except sr.RequestError as e:\n",
    "            return jsonify({'error': f'Speech Recognition error: {e}'}), 500 \"\"\"\n",
    "        \n",
    "\n",
    "@app.route('/api/convert-mp4-to-text', methods=['POST'])\n",
    "def convert_mp4_to_text():\n",
    "    file = os.path.abspath('./uploads/output.mp3') \n",
    "\n",
    "    if file: \n",
    "        mp3_filename = file\n",
    "        wav_filename = mp3_filename.replace('.mp3', '.wav') \n",
    "        AudioSegment.from_mp3(mp3_filename).export(wav_filename, format=\"wav\")\n",
    "\n",
    "    segment_dir = 'segments'\n",
    "    try:\n",
    "        if not os.path.exists(segment_dir):\n",
    "            os.mkdir(segment_dir)\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating directory: {e}\")\n",
    "\n",
    "    split_audio(wav_filename, segment_dir, segment_length_ms=60000)  \n",
    "    transcribed_texts = transcribe_audio_segments(segment_dir) \n",
    "    joined_text = join_transcribed_texts(transcribed_texts)\n",
    "    return jsonify({'text': joined_text})\n",
    "        \n",
    "\n",
    "@app.route('/api/translate_toar/<string:text>', methods=['GET'])\n",
    "def translate_to_ar(text):    \n",
    "    translator = Translator() \n",
    "    arabic_translation = translator.translate(text, src='en', dest='ar').text\n",
    "    return jsonify({'translated_txt': arabic_translation})\n",
    "\n",
    "\n",
    "@app.route('/api/translate_totr/<string:text>', methods=['GET'])\n",
    "def translate_to_tr(text):  \n",
    "    translator = Translator()    \n",
    "    turkish_translation = translator.translate(text, src='en', dest='tr').text\n",
    "    return jsonify({'translated_txt': turkish_translation})\n",
    "\n",
    "@app.route('/api/findtopic/<string:text>', methods=['GET'])\n",
    "def topic_finder(text):\n",
    "    pipe = pipeline(\"summarization\", model=\"google/pegasus-xsum\")\n",
    "    topic = pipe(text, max_length = 100)\n",
    "    topic = topic[0]['summary_text']\n",
    "    return jsonify({'topic': topic})\n",
    "\n",
    "@app.route('/api/findSummary/<string:text>', methods=['GET'])\n",
    "def summary_find(text):\n",
    "    pipe = pipeline(\"summarization\", model=\"google/pegasus-xsum\")\n",
    "    output = pipe(text, max_length = 200)\n",
    "    final_summary = output[0]['summary_text']\n",
    "\n",
    "    translator = Translator() \n",
    "    arabic_summary = translator.translate(final_summary, src='en', dest='ar').text\n",
    "    turkish_summary = translator.translate(final_summary, src='en', dest='tr').text\n",
    "\n",
    "    return jsonify({'summary_en': final_summary, 'summary_ar': arabic_summary, 'summary_tr': turkish_summary})\n",
    "\n",
    "\n",
    "@app.route('/api/sentiment/<string:text>', methods=['GET'])\n",
    "def sentiment(text):\n",
    "    nltk.download('vader_lexicon')\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    scores = analyzer.polarity_scores(text)\n",
    "    positive_percent = round(scores['pos'] * 100, 2)\n",
    "    negative_percent = round(scores['neg'] * 100, 2)\n",
    "\n",
    "    return jsonify({'positive': positive_percent, 'negative': negative_percent})\n",
    "\n",
    "if __name__ == '__main__': \n",
    "\n",
    "    app.run(debug=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

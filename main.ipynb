{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\haris\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Analysis Results:\n",
      "Positive Sentiment: 65.40%\n",
      "Negative Sentiment: 0.00%\n"
     ]
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "scores = analyzer.polarity_scores(text)\n",
    "positive_percent = scores['pos'] * 100\n",
    "negative_percent = scores['neg'] * 100\n",
    "\n",
    "print(\"Sentiment Analysis Results:\")\n",
    "print(f\"Positive Sentiment: {positive_percent:.2f}%\")\n",
    "print(f\"Negative Sentiment: {negative_percent:.2f}%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bert base model approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)okenizer_config.json: 100%|██████████| 48.0/48.0 [00:00<?, ?B/s]\n",
      "c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\haris\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 629/629 [00:00<?, ?B/s] \n",
      "Downloading (…)solve/main/vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 337kB/s]\n",
      "Downloading model.safetensors: 100%|██████████| 268M/268M [09:55<00:00, 450kB/s] \n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(text=text, return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "\n",
    "predicted_class_id = logits.argmax().item()\n",
    "temp = model.config.id2label[predicted_class_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'POSITIVE'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary and Topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [18/Oct/2023 19:43:46] \"POST /api/convert-mp3-to-text HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [18/Oct/2023 19:43:48] \"GET /api/findtopic/ HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [18/Oct/2023 19:44:36] \"GET /api/translate_to/American%20accent%20in%2010%20seconds%20is%20it%20is%20saying%20is%20he%20nice%20say%20easy%20nice%20easy%20nice%20easy%20nice%20nice HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [18/Oct/2023 19:44:41] \"GET /api/translate_totr/American%20accent%20in%2010%20seconds%20is%20it%20is%20saying%20is%20he%20nice%20say%20easy%20nice%20easy%20nice%20easy%20nice%20nice HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [18/Oct/2023 19:46:51] \"POST /api/convert-mp3-to-text HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [18/Oct/2023 19:46:56] \"GET /api/findtopic/ HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [18/Oct/2023 19:47:44] \"POST /api/convert-mp3-to-text HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [18/Oct/2023 19:47:49] \"GET /api/findtopic/ HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [18/Oct/2023 19:50:08] \"POST /api/convert-mp3-to-text HTTP/1.1\" 500 -\n",
      "127.0.0.1 - - [18/Oct/2023 19:50:53] \"POST /api/convert-mp3-to-text HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [18/Oct/2023 19:50:54] \"GET /api/findtopic/ HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [18/Oct/2023 19:52:39] \"POST /api/convert-mp3-to-text HTTP/1.1\" 200 -\n",
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-xsum and are newly initialized: ['model.encoder.embed_positions.weight', 'model.decoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "127.0.0.1 - - [18/Oct/2023 19:52:53] \"GET /api/findtopic/American%20accent%20in%2010%20seconds%20is%20it%20is%20saying%20is%20he%20nice%20say%20easy%20nice%20easy%20nice%20easy%20nice%20nice HTTP/1.1\" 200 -\n",
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-xsum and are newly initialized: ['model.encoder.embed_positions.weight', 'model.decoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Your max_length is set to 30, but your input_length is only 21. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=10)\n",
      "127.0.0.1 - - [18/Oct/2023 19:53:17] \"GET /api/findSummary/American%20accent%20in%2010%20seconds%20is%20it%20is%20saying%20is%20he%20nice%20say%20easy%20nice%20easy%20nice%20easy%20nice%20nice HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [18/Oct/2023 19:54:37] \"GET /api/translate_to/American%20accent%20in%2010%20seconds%20is%20it%20is%20saying%20is%20he%20nice%20say%20easy%20nice%20easy%20nice%20easy%20nice%20nice HTTP/1.1\" 404 -\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import speech_recognition as sr\n",
    "import pydub\n",
    "from googletrans import Translator\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModelForSeq2SeqLM\n",
    "from google.cloud import speech\n",
    "import subprocess\n",
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "import os\n",
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "from pydub import AudioSegment \n",
    "import speech_recognition as sr \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from googletrans import Translator  \n",
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app, origins=\"http://localhost:3000\", supports_credentials=True)\n",
    "\n",
    "\n",
    "@app.route('/api/convert-mp3-to-text', methods=['POST'])\n",
    "def convert_mp3_to_text():\n",
    "    if 'file' not in request.files:\n",
    "        return jsonify({'error': 'No file part'}), 400\n",
    "\n",
    "    file = request.files['file']\n",
    "    if file.filename == '':\n",
    "        return jsonify({'error': 'No selected file'}), 400\n",
    "\n",
    "    if file: \n",
    "        mp3_filename = os.path.join('uploads', file.filename)\n",
    "        file.save(mp3_filename)\n",
    " \n",
    "        wav_filename = mp3_filename.replace('.mp3', '.wav')\n",
    "        AudioSegment.from_mp3(mp3_filename).export(wav_filename, format=\"wav\")\n",
    " \n",
    "        recognizer = sr.Recognizer()\n",
    "        with sr.AudioFile(wav_filename) as source:\n",
    "            audio = recognizer.record(source)\n",
    "\n",
    "        try:\n",
    "            text = recognizer.recognize_google(audio)\n",
    "            return jsonify({'text': text})\n",
    "        except sr.UnknownValueError:\n",
    "            return jsonify({'error': 'Could not understand audio'}), 400\n",
    "        except sr.RequestError as e:\n",
    "            return jsonify({'error': f'Speech Recognition error: {e}'}), 500\n",
    "        \n",
    "\n",
    "@app.route('/api/translate_toar/<string:text>', methods=['GET'])\n",
    "def translate_to_ar(text):    \n",
    "    translator = Translator() \n",
    "    arabic_translation = translator.translate(text, src='en', dest='ar').text\n",
    "    return jsonify({'translated_txt': arabic_translation})\n",
    "\n",
    "\n",
    "@app.route('/api/translate_totr/<string:text>', methods=['GET'])\n",
    "def translate_to_tr(text):  \n",
    "    translator = Translator()    \n",
    "    turkish_translation = translator.translate(text, src='en', dest='tr').text\n",
    "    return jsonify({'translated_txt': turkish_translation})\n",
    "\n",
    "@app.route('/api/findtopic/<string:text>', methods=['GET'])\n",
    "def topic_finder(text):\n",
    "    pipe = pipeline(\"summarization\", model=\"google/pegasus-xsum\")\n",
    "    topic = pipe(text, max_length = 5)\n",
    "    topic = topic[0]['summary_text']\n",
    "    return jsonify({'topic': topic})\n",
    "\n",
    "@app.route('/api/findSummary/<string:text>', methods=['GET'])\n",
    "def summary_find(text):\n",
    "    pipe = pipeline(\"summarization\", model=\"google/pegasus-xsum\")\n",
    "    output = pipe(text, max_length = 30)\n",
    "    final_summary = output[0]['summary_text']\n",
    "\n",
    "    translator = Translator() \n",
    "    arabic_summary = translator.translate(final_summary, src='en', dest='ar').text\n",
    "    turkish_summary = translator.translate(final_summary, src='en', dest='tr').text\n",
    "\n",
    "    return jsonify({'summary_en': final_summary, 'summary_ar': arabic_summary, 'summary_tr': turkish_summary})\n",
    "\n",
    "if __name__ == '__main__': \n",
    "    app.run(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

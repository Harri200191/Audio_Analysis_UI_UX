{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import speech_recognition as sr \n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer \n",
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "from pydub import AudioSegment, silence \n",
    "from transformers import pipeline\n",
    "import spacy\n",
    "import moviepy.editor as mp \n",
    "from moviepy.editor import VideoFileClip  \n",
    "from googletrans import Translator\n",
    "from gensim.summarization import summarize\n",
    "from werkzeug.utils import secure_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [13/Mar/2024 22:44:44] \"POST /api/convert-mp3-to-text HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [13/Mar/2024 22:44:46] \"GET /api/translate_toen/American%20accent%20in%2010%20seconds%20is%20it%20is%20saying%20is%20he%20nice%20say%20easy%20nice%20easy%20nice%20easy%20nice%20nice HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [13/Mar/2024 22:44:47] \"GET /api/analyze-audio/American%20accent%20in%2010%20seconds%20is%20it%20is%20saying%20is%20he%20nice%20say%20easy%20nice%20easy%20nice%20easy%20nice%20nice HTTP/1.1\" 200 -\n",
      "config.json: 100%|██████████| 811/811 [00:00<?, ?B/s] \n",
      "model.safetensors:  19%|█▉        | 83.9M/438M [01:18<07:04, 833kB/s] Error while downloading from https://cdn-lfs.huggingface.co/unitary/toxic-bert/2c272885d24138df70bff1b3cd944a999bd6b41dad33209730aa8ba074f6ad09?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27model.safetensors%3B+filename%3D%22model.safetensors%22%3B&Expires=1710610928&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcxMDYxMDkyOH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby91bml0YXJ5L3RveGljLWJlcnQvMmMyNzI4ODVkMjQxMzhkZjcwYmZmMWIzY2Q5NDRhOTk5YmQ2YjQxZGFkMzMyMDk3MzBhYThiYTA3NGY2YWQwOT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=Y5gOsB2R3U6ZEPpHhh76am5xHxtgFPGLURMXzK70AwyTKgssiBXxD8sIpS5dPtx4kvL0KrCb8ZJ7CzKkkBYJZ6Yebe2O72EUuHVoKB%7EBpRRJ6Ye6fWQD42d65YxwB2JUD-t39646MQUwOUD5s%7EyPv3jVSdbsbblbxiyzYDw%7EzY3E%7Eu4kXhcJhF-u8i6y6A3ixm2HJpkES%7EMXD3l6KP15Vqwn6nRbUykzgBP4In97vSVBE5k4VPN5ydhSO9cN5n-UG02jCqiCdN3Ohq4LbQQNdu91Jc7jpAXIZBjLDtTpNnPty3ECEHPtznW6JWBRmEe9uBmJim-Vav4b5INRnD7h-g__&Key-Pair-Id=KVTP0A1DKRTAX: HTTPSConnectionPool(host='cdn-lfs.huggingface.co', port=443): Read timed out.\n",
      "Trying to resume download...\n",
      "model.safetensors:  19%|█▉        | 83.9M/438M [01:41<07:06, 830kB/s]\n",
      "[2024-03-13 22:46:35,441] ERROR in app: Exception on /api/findtopic/American accent in 10 seconds is it is saying is he nice say easy nice easy nice easy nice nice [GET]\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\flask\\app.py\", line 1455, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\flask\\app.py\", line 869, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\flask_cors\\extension.py\", line 176, in wrapped_function\n",
      "    return cors_after_request(app.make_response(f(*args, **kwargs)))\n",
      "                                                ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\flask\\app.py\", line 867, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\flask\\app.py\", line 852, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\haris\\AppData\\Local\\Temp\\ipykernel_27156\\883436317.py\", line 163, in topic_finder\n",
      "    pipe = pipeline(\"text-classification\", model=\"unitary/toxic-bert\")\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\transformers\\pipelines\\__init__.py\", line 870, in pipeline\n",
      "    framework, model = infer_framework_load_model(\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 282, in infer_framework_load_model\n",
      "    raise ValueError(\n",
      "ValueError: Could not load model unitary/toxic-bert with any of the following classes: (<class 'transformers.models.auto.modeling_auto.AutoModelForSequenceClassification'>, <class 'transformers.models.bert.modeling_bert.BertForSequenceClassification'>). See the original errors:\n",
      "\n",
      "while loading with AutoModelForSequenceClassification, an error is thrown:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\urllib3\\response.py\", line 737, in _error_catcher\n",
      "    yield\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\urllib3\\response.py\", line 862, in _raw_read\n",
      "    data = self._fp_read(amt, read1=read1) if not fp_closed else b\"\"\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\urllib3\\response.py\", line 845, in _fp_read\n",
      "    return self._fp.read(amt) if amt is not None else self._fp.read()\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\http\\client.py\", line 466, in read\n",
      "    s = self.fp.read(amt)\n",
      "        ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\socket.py\", line 706, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\ssl.py\", line 1278, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\ssl.py\", line 1134, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TimeoutError: The read operation timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\requests\\models.py\", line 816, in generate\n",
      "    yield from self.raw.stream(chunk_size, decode_content=True)\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\urllib3\\response.py\", line 1043, in stream\n",
      "    data = self.read(amt=amt, decode_content=decode_content)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\urllib3\\response.py\", line 935, in read\n",
      "    data = self._raw_read(amt)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\urllib3\\response.py\", line 861, in _raw_read\n",
      "    with self._error_catcher():\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\contextlib.py\", line 155, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\urllib3\\response.py\", line 742, in _error_catcher\n",
      "    raise ReadTimeoutError(self._pool, None, \"Read timed out.\") from e  # type: ignore[arg-type]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='cdn-lfs.huggingface.co', port=443): Read timed out.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 541, in http_get\n",
      "    for chunk in r.iter_content(chunk_size=DOWNLOAD_CHUNK_SIZE):\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\requests\\models.py\", line 822, in generate\n",
      "    raise ConnectionError(e)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='cdn-lfs.huggingface.co', port=443): Read timed out.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\urllib3\\connection.py\", line 198, in _new_conn\n",
      "    sock = connection.create_connection(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\urllib3\\util\\connection.py\", line 60, in create_connection\n",
      "    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\socket.py\", line 962, in getaddrinfo\n",
      "    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "socket.gaierror: [Errno 11001] getaddrinfo failed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 793, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 491, in _make_request\n",
      "    raise new_e\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 467, in _make_request\n",
      "    self._validate_conn(conn)\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 1099, in _validate_conn\n",
      "    conn.connect()\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\urllib3\\connection.py\", line 616, in connect\n",
      "    self.sock = sock = self._new_conn()\n",
      "                       ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\urllib3\\connection.py\", line 205, in _new_conn\n",
      "    raise NameResolutionError(self.host, self, e) from e\n",
      "urllib3.exceptions.NameResolutionError: <urllib3.connection.HTTPSConnection object at 0x0000026C7C5CAC10>: Failed to resolve 'cdn-lfs.huggingface.co' ([Errno 11001] getaddrinfo failed)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\requests\\adapters.py\", line 486, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 847, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\urllib3\\util\\retry.py\", line 515, in increment\n",
      "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='cdn-lfs.huggingface.co', port=443): Max retries exceeded with url: /unitary/toxic-bert/2c272885d24138df70bff1b3cd944a999bd6b41dad33209730aa8ba074f6ad09?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27model.safetensors%3B+filename%3D%22model.safetensors%22%3B&Expires=1710610928&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcxMDYxMDkyOH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby91bml0YXJ5L3RveGljLWJlcnQvMmMyNzI4ODVkMjQxMzhkZjcwYmZmMWIzY2Q5NDRhOTk5YmQ2YjQxZGFkMzMyMDk3MzBhYThiYTA3NGY2YWQwOT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=Y5gOsB2R3U6ZEPpHhh76am5xHxtgFPGLURMXzK70AwyTKgssiBXxD8sIpS5dPtx4kvL0KrCb8ZJ7CzKkkBYJZ6Yebe2O72EUuHVoKB~BpRRJ6Ye6fWQD42d65YxwB2JUD-t39646MQUwOUD5s~yPv3jVSdbsbblbxiyzYDw~zY3E~u4kXhcJhF-u8i6y6A3ixm2HJpkES~MXD3l6KP15Vqwn6nRbUykzgBP4In97vSVBE5k4VPN5ydhSO9cN5n-UG02jCqiCdN3Ohq4LbQQNdu91Jc7jpAXIZBjLDtTpNnPty3ECEHPtznW6JWBRmEe9uBmJim-Vav4b5INRnD7h-g__&Key-Pair-Id=KVTP0A1DKRTAX (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x0000026C7C5CAC10>: Failed to resolve 'cdn-lfs.huggingface.co' ([Errno 11001] getaddrinfo failed)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 269, in infer_framework_load_model\n",
      "    model = model_class.from_pretrained(model, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 566, in from_pretrained\n",
      "    return model_class.from_pretrained(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 3037, in from_pretrained\n",
      "    resolved_archive_file = cached_file(pretrained_model_name_or_path, filename, **cached_file_kwargs)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 430, in cached_file\n",
      "    resolved_file = hf_hub_download(\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py\", line 118, in _inner_fn\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1461, in hf_hub_download\n",
      "    http_get(\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 558, in http_get\n",
      "    return http_get(\n",
      "           ^^^^^^^^^\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 468, in http_get\n",
      "    r = _request_wrapper(\n",
      "        ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 425, in _request_wrapper\n",
      "    response = get_session().request(method=method, url=url, **params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\requests\\sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\requests\\sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py\", line 63, in send\n",
      "    return super().send(request, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\requests\\adapters.py\", line 519, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: (MaxRetryError('HTTPSConnectionPool(host=\\'cdn-lfs.huggingface.co\\', port=443): Max retries exceeded with url: /unitary/toxic-bert/2c272885d24138df70bff1b3cd944a999bd6b41dad33209730aa8ba074f6ad09?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27model.safetensors%3B+filename%3D%22model.safetensors%22%3B&Expires=1710610928&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcxMDYxMDkyOH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby91bml0YXJ5L3RveGljLWJlcnQvMmMyNzI4ODVkMjQxMzhkZjcwYmZmMWIzY2Q5NDRhOTk5YmQ2YjQxZGFkMzMyMDk3MzBhYThiYTA3NGY2YWQwOT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=Y5gOsB2R3U6ZEPpHhh76am5xHxtgFPGLURMXzK70AwyTKgssiBXxD8sIpS5dPtx4kvL0KrCb8ZJ7CzKkkBYJZ6Yebe2O72EUuHVoKB~BpRRJ6Ye6fWQD42d65YxwB2JUD-t39646MQUwOUD5s~yPv3jVSdbsbblbxiyzYDw~zY3E~u4kXhcJhF-u8i6y6A3ixm2HJpkES~MXD3l6KP15Vqwn6nRbUykzgBP4In97vSVBE5k4VPN5ydhSO9cN5n-UG02jCqiCdN3Ohq4LbQQNdu91Jc7jpAXIZBjLDtTpNnPty3ECEHPtznW6JWBRmEe9uBmJim-Vav4b5INRnD7h-g__&Key-Pair-Id=KVTP0A1DKRTAX (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x0000026C7C5CAC10>: Failed to resolve \\'cdn-lfs.huggingface.co\\' ([Errno 11001] getaddrinfo failed)\"))'), '(Request ID: 6ab0d6c1-229f-4a30-9f62-4e7b43c1c4ba)')\n",
      "\n",
      "while loading with BertForSequenceClassification, an error is thrown:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\urllib3\\connection.py\", line 198, in _new_conn\n",
      "    sock = connection.create_connection(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\urllib3\\util\\connection.py\", line 60, in create_connection\n",
      "    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\socket.py\", line 962, in getaddrinfo\n",
      "    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "socket.gaierror: [Errno 11001] getaddrinfo failed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 793, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 491, in _make_request\n",
      "    raise new_e\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 467, in _make_request\n",
      "    self._validate_conn(conn)\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 1099, in _validate_conn\n",
      "    conn.connect()\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\urllib3\\connection.py\", line 616, in connect\n",
      "    self.sock = sock = self._new_conn()\n",
      "                       ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\urllib3\\connection.py\", line 205, in _new_conn\n",
      "    raise NameResolutionError(self.host, self, e) from e\n",
      "urllib3.exceptions.NameResolutionError: <urllib3.connection.HTTPSConnection object at 0x0000026C00171F90>: Failed to resolve 'huggingface.co' ([Errno 11001] getaddrinfo failed)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\requests\\adapters.py\", line 486, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 847, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\urllib3\\util\\retry.py\", line 515, in increment\n",
      "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /unitary/toxic-bert/resolve/main/tf_model.h5 (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x0000026C00171F90>: Failed to resolve 'huggingface.co' ([Errno 11001] getaddrinfo failed)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 269, in infer_framework_load_model\n",
      "    model = model_class.from_pretrained(model, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 3077, in from_pretrained\n",
      "    if has_file(pretrained_model_name_or_path, TF2_WEIGHTS_NAME, **has_file_kwargs):\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 650, in has_file\n",
      "    r = requests.head(url, headers=headers, allow_redirects=False, proxies=proxies, timeout=10)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\requests\\api.py\", line 100, in head\n",
      "    return request(\"head\", url, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\requests\\api.py\", line 59, in request\n",
      "    return session.request(method=method, url=url, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\requests\\sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\requests\\sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\haris\\miniconda3\\envs\\forPyTorch\\Lib\\site-packages\\requests\\adapters.py\", line 519, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /unitary/toxic-bert/resolve/main/tf_model.h5 (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x0000026C00171F90>: Failed to resolve 'huggingface.co' ([Errno 11001] getaddrinfo failed)\"))\n",
      "\n",
      "\n",
      "\n",
      "127.0.0.1 - - [13/Mar/2024 22:46:35] \"GET /api/findtopic/American%20accent%20in%2010%20seconds%20is%20it%20is%20saying%20is%20he%20nice%20say%20easy%20nice%20easy%20nice%20easy%20nice%20nice HTTP/1.1\" 500 -\n"
     ]
    }
   ],
   "source": [
    "app = Flask(__name__)\n",
    "CORS(app, origins=\"http://localhost:3000\", supports_credentials=True)\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "@app.route('/api/analyze-audio/<string:text>', methods=['GET'])\n",
    "def analyze_text(text):\n",
    "    if len(text) == 0:\n",
    "        return jsonify({'error': 'No text provided'}), 400\n",
    "    \n",
    "    doc = nlp(text) \n",
    "    person_count = len([ent.text for ent in doc.ents if ent.label_ == \"PERSON\"]) \n",
    "    topics = [token.text for token in doc if token.is_alpha and not token.is_stop]\n",
    "    \n",
    "    return jsonify({'person_count' : person_count + 1 , 'topic' : topics[0], 'topic2' : topics[1]})\n",
    " \n",
    "\n",
    "@app.route('/api/convert-video-to-mp3', methods=['POST'])\n",
    "def convert_video_to_mp3():\n",
    "    if 'file' not in request.files:\n",
    "        return jsonify({'error': 'No file provided'}), 400\n",
    "\n",
    "    video_file = request.files['file']\n",
    "    if video_file.filename == '':\n",
    "        return jsonify({'error': 'No selected file'}), 400\n",
    "\n",
    "    if video_file: \n",
    "        try: \n",
    "            video_path = os.path.join('./uploads', video_file.filename)   \n",
    "            video_file.save(video_path)\n",
    " \n",
    "            audio_path = os.path.abspath('./uploads/output.mp3') \n",
    "            video_clip = VideoFileClip(video_path)\n",
    "            audio_clip = video_clip.audio\n",
    "            audio_clip.write_audiofile(audio_path)\n",
    "            audio_clip.close()\n",
    "            video_clip.close()\n",
    "\n",
    "            return jsonify({'message': 'Video converted to MP3 successfully', 'audio_file': audio_path}), 200\n",
    "        except Exception as e:\n",
    "            return jsonify({'error': 'Conversion error', 'details': str(e)}), 500\n",
    "\n",
    "\n",
    "def get_audio_length(audio_filename):\n",
    "    audio = AudioSegment.from_file(audio_filename)\n",
    "    return len(audio) / 1000  # Return length in seconds    \n",
    "\n",
    "def split_audio_with_timestamps(input_audio, output_dir, segment_length_ms=60000):\n",
    "    print(\"Processing input audio...\")\n",
    "    audio = AudioSegment.from_file(input_audio)\n",
    "    audio_length = len(audio)\n",
    "    silence_ranges = silence.detect_nonsilent(audio, min_silence_len=100, silence_thresh=-40)\n",
    "    \n",
    "    segment_texts = []\n",
    "    segment_start_times = []\n",
    "    segment_end_times = []\n",
    "    \n",
    "    for i, (start, end) in enumerate(silence_ranges):\n",
    "        segment_start_times.append(start)\n",
    "        segment_end_times.append(end)\n",
    "        segment = audio[start:end]\n",
    "        segment.export(os.path.join(output_dir, f\"segment_{i}.wav\"), format=\"wav\")\n",
    "        \n",
    "    if len(segment_start_times) > 0:\n",
    "        segment_start_times.insert(0, 0)\n",
    "        segment_end_times.append(audio_length)\n",
    "        for i in range(len(segment_start_times) - 1):\n",
    "            start_time = segment_start_times[i] / 1000\n",
    "            end_time = segment_end_times[i] / 1000\n",
    "            segment_texts.append(f\"[{start_time}:{end_time}] \" + transcribe_audio_segment(os.path.join(output_dir, f\"segment_{i}.wav\")))\n",
    "    \n",
    "    return segment_texts\n",
    "\n",
    "def transcribe_audio_segment(audio_file):\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.AudioFile(audio_file) as source:\n",
    "        audio_text = recognizer.record(source)\n",
    "        text = recognizer.recognize_google(audio_text)\n",
    "    return text\n",
    "\n",
    "def join_transcribed_texts(texts):\n",
    "    return \" \".join(texts)\n",
    "\n",
    "def convert_mp3_to_wav(mp3_filename):\n",
    "    wav_filename = mp3_filename.replace('.mp3', '.wav')\n",
    "    audio = AudioSegment.from_mp3(mp3_filename)\n",
    "    audio.export(wav_filename, format=\"wav\")\n",
    "    return wav_filename\n",
    "\n",
    "@app.route('/api/convert-mp3-to-text', methods=['POST'])\n",
    "def convert_mp3_to_text():\n",
    "    if 'file' not in request.files:\n",
    "        return jsonify({'error': 'No file part'}), 400\n",
    "\n",
    "    file = request.files['file']\n",
    "    language = request.form['language']\n",
    "    \n",
    "    if file.filename == '':\n",
    "        return jsonify({'error': 'No selected file'}), 400\n",
    "\n",
    "    if file:  \n",
    "        mp3_filename = os.path.join('uploads', file.filename)\n",
    "        file.save(mp3_filename)\n",
    "        segment_dir = 'segments'  \n",
    "        os.makedirs(segment_dir, exist_ok=True)\n",
    "        audio_length = get_audio_length(mp3_filename)\n",
    "\n",
    "        if audio_length > 60:\n",
    "            split_audio_with_timestamps(mp3_filename, segment_dir, segment_length_ms=60000)\n",
    "            transcribed_texts = transcribe_audio_segment(segment_dir) \n",
    "            joined_text = join_transcribed_texts(transcribed_texts)\n",
    "        else:\n",
    "            recognizer = sr.Recognizer()\n",
    "\n",
    "            wav_filename = convert_mp3_to_wav(mp3_filename)\n",
    "\n",
    "            with sr.AudioFile(wav_filename) as source:\n",
    "                audio_text = recognizer.record(source)\n",
    "                text = recognizer.recognize_google(audio_text, language=language)\n",
    "                joined_text = text\n",
    "        \n",
    "        return jsonify({'text': joined_text})\n",
    "    \n",
    "@app.route('/api/translate_toar/<string:text>', methods=['GET'], endpoint='translate_to_ar')\n",
    "def translate_to_ar(text):    \n",
    "    translator = Translator() \n",
    "    arabic_translation = translator.translate(text,  src='auto', dest='ar').text\n",
    "    return jsonify({'translated_txt': arabic_translation})\n",
    "\n",
    "@app.route('/api/translate_totr/<string:text>', methods=['GET'], endpoint='translate_to_tr')\n",
    "def translate_to_tr(text):  \n",
    "    translator = Translator()    \n",
    "\n",
    "    turkish_translation = translator.translate(text, src='auto', dest='tr').text\n",
    "    return jsonify({'translated_txt': turkish_translation})\n",
    "\n",
    "@app.route('/api/translate_toen/<string:text>', methods=['GET'], endpoint='translate_to_en')\n",
    "def translate_to_en(text):  \n",
    "    translator = Translator()    \n",
    "\n",
    "    english_translation = translator.translate(text, src='auto', dest='en').text\n",
    "    return jsonify({'translated_txt': english_translation})\n",
    "\n",
    "@app.route('/api/translate_tohi/<string:text>', methods=['GET'], endpoint='translate_to_hi')\n",
    "def translate_to_hi(text):  \n",
    "    translator = Translator()    \n",
    "\n",
    "    hindi_translation = translator.translate(text, src='auto', dest='hi').text\n",
    "    return jsonify({'translated_txt': hindi_translation})\n",
    "\n",
    "def add_newlines_every_n_words(input_string, n=10):\n",
    "    words = input_string.split()\n",
    "    output_string = ''\n",
    "    for i, word in enumerate(words):\n",
    "        if i > 0 and i % n == 0:\n",
    "            output_string += '\\n'\n",
    "        output_string += word + ' '\n",
    "    return output_string.strip()\n",
    "\n",
    "@app.route('/api/findtopic/<string:text>', methods=['GET'])\n",
    "def topic_finder(text):\n",
    "    \n",
    "    pipe = pipeline(\"text-classification\", model=\"unitary/toxic-bert\")\n",
    "    pipe2 = pipeline(\"summarization\", model=\"google/pegasus-xsum\")\n",
    "\n",
    "    topic = pipe(text)  \n",
    "    topic = topic[0]['label']\n",
    "\n",
    "    topic2 = pipe2(text, max_length = 20)\n",
    "    topic2 = topic2[0]['summary_text']\n",
    "    \n",
    "    return jsonify({'topic': topic, 'topic2': topic2})\n",
    "\n",
    "@app.route('/api/findSummary/<string:text>', methods=['GET'])\n",
    "def summary_find(text):\n",
    "    pipe = pipeline(\"summarization\", model=\"google/pegasus-xsum\")\n",
    "    \n",
    "    temp = add_newlines_every_n_words(text, 30)\n",
    "    try: \n",
    "        summary = summarize(temp)\n",
    "        print(\"len: \", len(summary))\n",
    "    except:\n",
    "        output = pipe(text) \n",
    "        summary = output[0]['summary_text']\n",
    "             \n",
    "    translator = Translator() \n",
    "    arabic_summary = translator.translate(summary, src='en', dest='ar').text\n",
    "    turkish_summary = translator.translate(summary, src='en', dest='tr').text\n",
    "\n",
    "    return jsonify({'summary_en': summary, 'summary_ar': arabic_summary, 'summary_tr': turkish_summary})\n",
    "\n",
    "\n",
    "@app.route('/api/sentiment/<string:text>', methods=['GET'])\n",
    "def sentiment(text):\n",
    "    nltk.download('vader_lexicon')\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    scores = analyzer.polarity_scores(text)\n",
    "    positive_percent = round(scores['pos'] * 100, 2)\n",
    "    negative_percent = round(scores['neg'] * 100, 2)\n",
    "\n",
    "    total = positive_percent + negative_percent\n",
    "    fin_pos = round((positive_percent/total)*100, 2)\n",
    "    fin_neg = round((negative_percent/total)*100, 2)\n",
    "\n",
    "    return jsonify({'positive': fin_pos, 'negative': fin_neg})\n",
    "\n",
    "        \n",
    "if __name__ == '__main__': \n",
    "    app.run(debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
